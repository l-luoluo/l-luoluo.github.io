<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>优化方法 on 心有所向，日复一日，必有精进</title>
    <link>http://localhost:1313/tags/%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/</link>
    <description>Recent content from 心有所向，日复一日，必有精进</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    
    <managingEditor>xxx@example.com (落-luo)</managingEditor>
    <webMaster>xxx@example.com (落-luo)</webMaster>
    
    <copyright>本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！</copyright>
    
    <lastBuildDate>Fri, 21 Nov 2025 15:00:00 +0800</lastBuildDate>
    
    
    <atom:link href="http://localhost:1313/tags/%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/index.xml" rel="self" type="application/rss&#43;xml" />
    

    
    

    <item>
      <title>基础优化方法</title>
      <link>http://localhost:1313/post/no.32/</link>
      <pubDate>Fri, 21 Nov 2025 15:00:00 &#43;0800</pubDate>
      <author>xxx@example.com (落-luo)</author>
      <guid>http://localhost:1313/post/no.32/</guid>
      <description>
        <![CDATA[<h1>基础优化方法</h1><p>作者：落-luo（xxx@example.com）</p>
        
          <h3 id="链接">
<a class="header-anchor" href="#%e9%93%be%e6%8e%a5"></a>
链接
</h3><p><a href="https://courses.d2l.ai/zh-v2/assets/pdfs/part-0_9.pdf">基础优化方法</a></p>
<h3 id="1梯度下降">
<a class="header-anchor" href="#1%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d"></a>
1.梯度下降
</h3><p>梯度下降是一种优化算法，用于最小化损失函数。它的基本思想是通过迭代更新参数，使损失函数达到最小值。</p>
<p>梯度下降的更新规则如下：
</p>
        
        <hr><p>本文2025-11-21首发于<a href='http://localhost:1313/'>心有所向，日复一日，必有精进</a>，最后修改于2025-11-21</p>]]>
      </description>
      
        <category>跟着李沐学AI</category><category>动手学深度学V2</category><category>原理</category>
      
    </item>
    
  </channel>
</rss>
