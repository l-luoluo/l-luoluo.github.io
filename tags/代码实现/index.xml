<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>代码实现 on 心有所向，日复一日，必有精进</title>
    <link>http://localhost:1313/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</link>
    <description>Recent content from 心有所向，日复一日，必有精进</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    
    <managingEditor>xxx@example.com (落-luo)</managingEditor>
    <webMaster>xxx@example.com (落-luo)</webMaster>
    
    <copyright>本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！</copyright>
    
    <lastBuildDate>Tue, 18 Nov 2025 15:00:00 +0800</lastBuildDate>
    
    
    <atom:link href="http://localhost:1313/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/index.xml" rel="self" type="application/rss&#43;xml" />
    

    
    

    <item>
      <title>线性代数——代码实现</title>
      <link>http://localhost:1313/post/no.26/</link>
      <pubDate>Tue, 18 Nov 2025 15:00:00 &#43;0800</pubDate>
      <author>xxx@example.com (落-luo)</author>
      <guid>http://localhost:1313/post/no.26/</guid>
      <description>
        <![CDATA[<h1>线性代数——代码实现</h1><p>作者：落-luo（xxx@example.com）</p>
        
          <h3 id="链接">
<a class="header-anchor" href="#%e9%93%be%e6%8e%a5"></a>
链接
</h3><p><a href="https://courses.d2l.ai/zh-v2/assets/notebooks/chapter_preliminaries/linear-algebra.slides.html#/">动手学深度学V2</a></p>
<h3 id="需要导入的库">
<a class="header-anchor" href="#%e9%9c%80%e8%a6%81%e5%af%bc%e5%85%a5%e7%9a%84%e5%ba%93"></a>
需要导入的库
</h3><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span></code></pre></div><h4 id="1标量">
<a class="header-anchor" href="#1%e6%a0%87%e9%87%8f"></a>
1.标量
</h4><p>标量由只有一个元素的张量表示</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">/</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="n">y</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))
</span></span></code></pre></div><h4 id="2向量">
<a class="header-anchor" href="#2%e5%90%91%e9%87%8f"></a>
2.向量
</h4><p>可以将向量视为标量值组成的列表</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([0, 1, 2, 3])
</span></span></code></pre></div><h5 id="21-访问向量的元素">
<a class="header-anchor" href="#21-%e8%ae%bf%e9%97%ae%e5%90%91%e9%87%8f%e7%9a%84%e5%85%83%e7%b4%a0"></a>
2.1 访问向量的元素
</h5><p>可以通过张量的索引来访问任一元素</p>
        
        <hr><p>本文2025-11-18首发于<a href='http://localhost:1313/'>心有所向，日复一日，必有精进</a>，最后修改于2025-11-18</p>]]>
      </description>
      
        <category>跟着李沐学AI</category><category>动手学深度学V2</category>
      
    </item>
    
    

    <item>
      <title>AlexNet模型-模型代码搭建</title>
      <link>http://localhost:1313/post/no.12/</link>
      <pubDate>Sun, 09 Nov 2025 15:00:00 &#43;0800</pubDate>
      <author>xxx@example.com (落-luo)</author>
      <guid>http://localhost:1313/post/no.12/</guid>
      <description>
        <![CDATA[<h1>AlexNet模型-模型代码搭建</h1><p>作者：落-luo（xxx@example.com）</p>
        
          <h3 id="前言">
<a class="header-anchor" href="#%e5%89%8d%e8%a8%80"></a>
前言
</h3><p>之后的文章只会介绍模型的代码搭建，而<a href="https://l-luoluo.github.io/post/no.9/">训练代码</a>和<a href="https://l-luoluo.github.io/post/no.10/">测试代码</a>
在链接里面有详细的代码，这里就不重复介绍了。</p>
<h3 id="模型代码搭建">
<a class="header-anchor" href="#%e6%a8%a1%e5%9e%8b%e4%bb%a3%e7%a0%81%e6%90%ad%e5%bb%ba"></a>
模型代码搭建
</h3><h4 id="1-导入所需的库">
<a class="header-anchor" href="#1-%e5%af%bc%e5%85%a5%e6%89%80%e9%9c%80%e7%9a%84%e5%ba%93"></a>
1. 导入所需的库
</h4><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span></code></pre></div><h4 id="2-模型搭建">
<a class="header-anchor" href="#2-%e6%a8%a1%e5%9e%8b%e6%90%ad%e5%bb%ba"></a>
2. 模型搭建
</h4><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ReLU</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">c1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">s2</span> <span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">c3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">s4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">c5</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">c6</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">c7</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">s8</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">6</span><span class="o">*</span><span class="mi">6</span><span class="o">*</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span></code></pre></div><p><span style="font-size: 20px;">其中c代表卷积层，s代表池化层，fc代表全连接层。</span></p>
        
        <hr><p>本文2025-11-09首发于<a href='http://localhost:1313/'>心有所向，日复一日，必有精进</a>，最后修改于2025-11-09</p>]]>
      </description>
      
        <category>炮哥带你学</category><category>pytorch与经典卷积神经网络</category><category>实践</category>
      
    </item>
    
    

    <item>
      <title>LeNet模型-模型代码搭建</title>
      <link>http://localhost:1313/post/no.11/</link>
      <pubDate>Sat, 08 Nov 2025 15:00:00 &#43;0800</pubDate>
      <author>xxx@example.com (落-luo)</author>
      <guid>http://localhost:1313/post/no.11/</guid>
      <description>
        <![CDATA[<h1>LeNet模型-模型代码搭建</h1><p>作者：落-luo（xxx@example.com）</p>
        
          <h3 id="前言">
<a class="header-anchor" href="#%e5%89%8d%e8%a8%80"></a>
前言
</h3><p>这篇文章主要为LeNet模型的代码搭建，代码主要参考了炮哥带你学的视频，但是我自己也添加了一些注释，希望可以帮助到大家。
代码运行的详细环境搭建可以参考炮哥的视频<a href="https://www.bilibili.com/video/BV1e34y1M7wR?spm_id_from=333.788.videopod.episodes&amp;vd_source=dd1d3ef45b7fa14b9604277983db3fc3&amp;p=22">代码环境搭建</a></p>
        
        <hr><p>本文2025-11-08首发于<a href='http://localhost:1313/'>心有所向，日复一日，必有精进</a>，最后修改于2025-11-08</p>]]>
      </description>
      
        <category>炮哥带你学</category><category>pytorch与经典卷积神经网络</category><category>实践</category>
      
    </item>
    
    

    <item>
      <title>LeNet模型-测试代码搭建</title>
      <link>http://localhost:1313/post/no.10/</link>
      <pubDate>Sat, 08 Nov 2025 15:00:00 &#43;0800</pubDate>
      <author>xxx@example.com (落-luo)</author>
      <guid>http://localhost:1313/post/no.10/</guid>
      <description>
        <![CDATA[<h1>LeNet模型-测试代码搭建</h1><p>作者：落-luo（xxx@example.com）</p>
        
          <h3 id="前言">
<a class="header-anchor" href="#%e5%89%8d%e8%a8%80"></a>
前言
</h3><p><strong>同样这一套的代码依旧是一套通用的代码，可以反复于其他模型的测试。</strong></p>
<h3 id="测试代码搭建">
<a class="header-anchor" href="#%e6%b5%8b%e8%af%95%e4%bb%a3%e7%a0%81%e6%90%ad%e5%bb%ba"></a>
测试代码搭建
</h3><h4 id="1-导入必要的库">
<a class="header-anchor" href="#1-%e5%af%bc%e5%85%a5%e5%bf%85%e8%a6%81%e7%9a%84%e5%ba%93"></a>
1. 导入必要的库
</h4><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">Data</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">FashionMNIST</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">LeNet</span>
</span></span></code></pre></div><p>同样的，这里的模型文件也需要和测试代码在同一个目录下，并且要和模型文件的文件名一致。
可以参考</p>
        
        <hr><p>本文2025-11-08首发于<a href='http://localhost:1313/'>心有所向，日复一日，必有精进</a>，最后修改于2025-11-08</p>]]>
      </description>
      
        <category>炮哥带你学</category><category>pytorch与经典卷积神经网络</category><category>实践</category>
      
    </item>
    
    

    <item>
      <title>LeNet模型-训练代码搭建</title>
      <link>http://localhost:1313/post/no.9/</link>
      <pubDate>Fri, 07 Nov 2025 15:00:00 &#43;0800</pubDate>
      <author>xxx@example.com (落-luo)</author>
      <guid>http://localhost:1313/post/no.9/</guid>
      <description>
        <![CDATA[<h1>LeNet模型-训练代码搭建</h1><p>作者：落-luo（xxx@example.com）</p>
        
          <h3 id="前言">
<a class="header-anchor" href="#%e5%89%8d%e8%a8%80"></a>
前言
</h3><p>本片文章主要是通用的模型训练代码搭建，这个代码搭建完成后，我们就可以直接使用这个代码来训练我们的模型了。
而且后面的模型都可以复用这一套的代码，只需要修改一下模型的参数即可。</p>
        
        <hr><p>本文2025-11-07首发于<a href='http://localhost:1313/'>心有所向，日复一日，必有精进</a>，最后修改于2025-11-07</p>]]>
      </description>
      
        <category>炮哥带你学</category><category>pytorch与经典卷积神经网络</category><category>实践</category>
      
    </item>
    
    

    <item>
      <title>线性回归模型案例的代码复现</title>
      <link>http://localhost:1313/post/no.3/</link>
      <pubDate>Sun, 02 Nov 2025 15:00:00 &#43;0800</pubDate>
      <author>xxx@example.com (落-luo)</author>
      <guid>http://localhost:1313/post/no.3/</guid>
      <description>
        <![CDATA[<h1>线性回归模型案例的代码复现</h1><p>作者：落-luo（xxx@example.com）</p>
        
          <h4 id="案例">
<a class="header-anchor" href="#%e6%a1%88%e4%be%8b"></a>
案例
</h4><p><img src="/img/NO.1/%E5%9B%BE2.png" alt=""></p>
<p>上述就是我们要解决的问题，即通过线性回归模型来对未知的y值进行预测。下面我们将通过代码复现一下这个案例。</p>
<h4 id="代码复现">
<a class="header-anchor" href="#%e4%bb%a3%e7%a0%81%e5%a4%8d%e7%8e%b0"></a>
代码复现
</h4><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="err">#</span> <span class="err">定义数据集</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">#</span> <span class="err">定义数据特征</span>
</span></span><span class="line"><span class="cl"><span class="err">x_data</span> <span class="err">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">#</span> <span class="err">定义数据标签</span>
</span></span><span class="line"><span class="cl"><span class="err">y_data</span> <span class="err">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">#</span> <span class="err">初始化参数W</span>
</span></span><span class="line"><span class="cl"><span class="err">w</span> <span class="err">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">#定义线性回归模型</span>
</span></span><span class="line"><span class="cl"><span class="err">def</span> <span class="err">forword(x):</span>
</span></span><span class="line"><span class="cl">    <span class="err">return</span> <span class="err">x</span> <span class="err">*</span> <span class="err">w</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">#定义损失函数</span>
</span></span><span class="line"><span class="cl"><span class="err">def</span> <span class="err">cost(xs,</span> <span class="err">ys):</span>
</span></span><span class="line"><span class="cl">    <span class="err">costvalue</span> <span class="err">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="err">for</span> <span class="err">x</span> <span class="err">,</span> <span class="err">y</span> <span class="err">in</span> <span class="err">zip(xs,</span> <span class="err">ys):</span>
</span></span><span class="line"><span class="cl">        <span class="err">y_pred</span> <span class="err">=</span> <span class="err">forword(x)</span>
</span></span><span class="line"><span class="cl">        <span class="err">costvalue</span> <span class="err">+=</span> <span class="err">(y_pred</span> <span class="err">-</span> <span class="err">y)**</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="err">return</span> <span class="err">costvalue</span> <span class="err">/</span> <span class="err">len(xs)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">#定义计算梯度的函数</span>
</span></span><span class="line"><span class="cl"><span class="err">def</span> <span class="err">gradient(xs,</span> <span class="err">ys):</span>
</span></span><span class="line"><span class="cl">    <span class="err">grad</span> <span class="err">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="err">for</span> <span class="err">x,</span> <span class="err">y</span> <span class="err">in</span> <span class="err">zip(xs,</span> <span class="err">ys):</span>
</span></span><span class="line"><span class="cl">        <span class="err">grad</span> <span class="err">+=</span> <span class="mi">2</span> <span class="err">*</span> <span class="err">x</span> <span class="err">*</span> <span class="err">(x</span> <span class="err">*</span> <span class="err">w</span> <span class="err">-</span> <span class="err">y)</span>
</span></span><span class="line"><span class="cl">    <span class="err">return</span> <span class="err">grad</span> <span class="err">/</span> <span class="err">len(xs)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">for</span> <span class="err">epoch</span> <span class="err">in</span> <span class="err">range(</span><span class="mi">100</span><span class="err">):</span>
</span></span><span class="line"><span class="cl">    <span class="err">#计算误差损失</span>
</span></span><span class="line"><span class="cl">    <span class="err">cost_val</span> <span class="err">=</span> <span class="err">cost(x_data,</span> <span class="err">y_data)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="err">grad_val</span> <span class="err">=</span> <span class="err">gradient(x_data,</span> <span class="err">y_data)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="err">w</span> <span class="err">=w</span><span class="mf">-0.01</span> <span class="err">*</span> <span class="err">grad_val</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="err">print(&#39;训练轮次：&#39;,</span> <span class="err">epoch,</span> <span class="s2">&#34;w=&#34;</span><span class="err">,</span> <span class="err">w,</span><span class="s2">&#34;loss&#34;</span><span class="err">,</span> <span class="err">cost_val)</span>
</span></span><span class="line"><span class="cl">    
</span></span></code></pre></div><h4 id="结果">
<a class="header-anchor" href="#%e7%bb%93%e6%9e%9c"></a>
结果
</h4><p>运行上述的代码，我们不难得出当w接近2时，损失函数也接近0，这也验证了我们的模型是正确的。</p>
        
        <hr><p>本文2025-11-02首发于<a href='http://localhost:1313/'>心有所向，日复一日，必有精进</a>，最后修改于2025-11-02</p>]]>
      </description>
      
        <category>炮哥带你学</category><category>pytorch与经典卷积神经网络</category><category>实践</category>
      
    </item>
    
  </channel>
</rss>
