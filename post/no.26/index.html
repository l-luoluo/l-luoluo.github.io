<!doctype html>
<html
  lang="zh-cn" 
  data-theme-mode="auto"
  >
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8" />
<meta
  name="viewport"
  content="width=device-width, initial-scale=1, shrink-to-fit=no"
/><title>
  线性代数——代码实现 | 落-luo
</title>
<meta
  name="description"
  content="文中所有所用资料均来自：动手学深度学V2"
/><script>
  window.siteConfig = JSON.parse("{\"anchor_icon\":null,\"base\":\"http://localhost:1313/\",\"clipboard\":{\"copyright\":{\"count\":50,\"enable\":false,\"license_type\":\"by-nc-sa\"},\"fail\":{\"en\":\"Copy failed (ﾟ⊿ﾟ)ﾂ\",\"ja\":\"コピー失敗 (ﾟ⊿ﾟ)ﾂ\",\"pt-br\":\"Falha ao copiar (ﾟ⊿ﾟ)ﾂ\",\"zh-cn\":\"复制失败 (ﾟ⊿ﾟ)ﾂ\",\"zh-tw\":\"複製失敗 (ﾟ⊿ﾟ)ﾂ\"},\"success\":{\"en\":\"Copy successfully (*^▽^*)\",\"ja\":\"コピー成功 (*^▽^*)\",\"pt-br\":\"Copiado com sucesso (*^▽^*)\",\"zh-cn\":\"复制成功 (*^▽^*)\",\"zh-tw\":\"複製成功 (*^▽^*)\"}},\"code_block\":{\"expand\":true},\"i18n_languages\":[{\"Lang\":\"en\",\"LanguageName\":\"English\",\"LanguageCode\":\"\",\"Title\":\"\",\"LanguageDirection\":\"\",\"Weight\":1,\"Disabled\":false},{\"Lang\":\"ja\",\"LanguageName\":\"日本語\",\"LanguageCode\":\"\",\"Title\":\"\",\"LanguageDirection\":\"\",\"Weight\":1,\"Disabled\":false},{\"Lang\":\"zh-cn\",\"LanguageName\":\"简体中文\",\"LanguageCode\":\"\",\"Title\":\"\",\"LanguageDirection\":\"\",\"Weight\":1,\"Disabled\":false},{\"Lang\":\"zh-tw\",\"LanguageName\":\"繁體中文\",\"LanguageCode\":\"\",\"Title\":\"\",\"LanguageDirection\":\"\",\"Weight\":1,\"Disabled\":false}],\"icon_font\":\"4552607_4k4bc36ef96\",\"outdate\":{\"daysago\":180,\"enable\":false,\"message\":{\"en\":\"This article was last updated on {time}. Please note that the content may no longer be applicable.\",\"ja\":\"この記事は最終更新日：{time}。記載内容が現在有効でない可能性がありますのでご注意ください。\",\"pt-br\":\"Este artigo foi atualizado pela última vez em {time}. Observe que o conteúdo pode não ser mais aplicável.\",\"zh-cn\":\"本文最后更新于 {time}，请注意文中内容可能已不适用。\",\"zh-tw\":\"本文最後更新於 {time}，請注意文中內容可能已不適用。\"}}}");
  
</script>
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
  rel="preload"
  as="style"
  href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7cNoto%20Serif%20SC:400,400italic,700,700italic%7c&amp;display=swap"
/>
<link
  rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7cNoto%20Serif%20SC:400,400italic,700,700italic%7c&amp;display=swap"
  media="print"
  onload="this.media='all'"
/>
<link
    rel="preload"
    href="//at.alicdn.com/t/c/font_4552607_4k4bc36ef96.woff2"
    as="font"
    type="font/woff2"
    crossorigin="anonymous"
  /><link rel="stylesheet" href="/css/loader.css" />
<meta property="og:type" content="website" />
  <meta property="og:title" content="线性代数——代码实现 | 落-luo" />
  <meta
    property="og:description"
    content="文中所有所用资料均来自：动手学深度学V2"
  />
  <meta property="og:url" content="http://localhost:1313/post/no.26/" />
  <meta
    property="og:site_name"
    content="心有所向，日复一日，必有精进"
  />
  <meta
    property="og:image"
    content="/"
  />
  <meta property="article:author" content="落-luo" />
  <meta property="article:published_time" content="2025-11-18T15:00:00&#43;08:00" />
  <meta property="article:modified_time" content="2025-11-18T15:00:00&#43;08:00" /><meta property="article:tag" content="线性代数代码实现" /><meta name="twitter:card" content="summary" />
  <meta name="twitter:image" content="/" />
<link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/main.css" />
<link
    rel="preload"
    as="style"
    href="https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.css"
    integrity="sha384-IfxC36XL/toUyJ939C73PcgMuRzAZuIzZxE38drsmO5p6jD7ei&#43;Zx/1oA/0l8ysE" crossorigin="anonymous"onload="this.onload=null;this.rel='stylesheet'"
  /><link
    rel="preload"
    as="style"
    href="https://npm.webcache.cn/katex@0.16.24/dist/katex.min.css"
    integrity="sha384-tTgKLjMYmJr94v8qu2PE5MUGSMbyN2xiH266JUB3gpm8vnnJywd1dWSOEfrFz&#43;YI" crossorigin="anonymous"onload="this.onload=null;this.rel='stylesheet'"
  /><script
    src="https://npm.webcache.cn/pace-js@1.2.4/pace.min.js"
    integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous"></script><link
    rel="stylesheet"
    href="https://npm.webcache.cn/@reimujs/aos@0.1.2/dist/aos.css"
    integrity="sha384-GMRP93c6Hkz9JVKGAuRR3nTS7M07RwPgTFenXiosjq2VbVgvdDNcz1g6Mkj8AONa" crossorigin="anonymous"/></head>
  <body><div id='loader'>
    <div class="loading-left-bg loading-bg"></div>
    <div class="loading-right-bg loading-bg"></div>
    <div class="spinner-box">
      <div class="loading-taichi rotate"><svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="https://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
            <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="var(--red-1, #ff5252)" />
            <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z 
          M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95z" fill="var(--red-1, #ff5252)" />
          </svg></div><div class="loading-word">少女祈祷中...</div>
    </div>
  </div>
  </div>
  <script>
    var time = null;
    var loaderEl = document.getElementById('loader');
    var startLoading = () => {
      time = Date.now();
      loaderEl.classList.remove("loading");
    }
    var hideLoader = () => {
      document.body.style.overflow = 'auto';
      loader.classList.add('loading');
    };

    var endLoading = () => {
      if (!time) {
        hideLoader();
      } else {
        if (Date.now() - time > 500) {
          time = null;
          hideLoader();
        } else {
          setTimeout(endLoading, 500 - (Date.now() - time));
          time = null;
        }
      }
    }
    window.addEventListener('DOMContentLoaded', endLoading);
    loaderEl.addEventListener('click', endLoading);
  </script><div id="copy-tooltip"></div>
<div id="lang-tooltip">
本文章没有找到对应的语言版本
</div>
<div id="heatmap-tooltip"></div><div id="container">
      <div id="wrap"><div id="header-nav">
  <nav id="main-nav" aria-label="Primary navigation"><a class="main-nav-link-wrap" href="/">
        <div class='main-nav-icon icon rotate'>&#xe62b;</div>
        <span class="main-nav-link">首页</span>
      </a><a class="main-nav-link-wrap" href="/archives">
        <div class='main-nav-icon icon rotate'>&#xe62b;</div>
        <span class="main-nav-link">归档</span>
      </a><a class="main-nav-link-wrap" href="/about">
        <div class='main-nav-icon icon rotate'>&#xe62b;</div>
        <span class="main-nav-link">关于</span>
      </a><a class="main-nav-link-wrap" href="/friend">
        <div class='main-nav-icon icon rotate'>&#xe62b;</div>
        <span class="main-nav-link">友链</span>
      </a><a id="main-nav-toggle" class="nav-icon" aria-label="Toggle navigation" role="button"></a>
  </nav>
  <nav id="sub-nav" aria-label="Secondary navigation"></nav><nav id="i18n-nav" aria-label="Language selection">
      <div class="custom-dropdown">
        <div class="select-selected" id="select-selected" role="button" aria-haspopup="listbox" aria-expanded="false" aria-label="Language menu">
          <span id="nav-language-btn" class="nav-icon" style="padding: 0 20px 0 0"></span>
          <span id="selected-lang">简体中文</span>
        </div>
        <ul class="select-items" id="select-items" role="listbox" aria-label="Languages"><li data-value="en" role="option" arial-selected="false" >English</li><li data-value="ja" role="option" arial-selected="false" >日本語</li><li data-value="zh-cn" role="option" class="selected" arial-selected="true" >简体中文</li><li data-value="zh-tw" role="option" arial-selected="false" >繁體中文</li></ul>
      </div>
      <script>
        var selectSelected = document.getElementById("select-selected");
        var selectedLang = document.getElementById("selected-lang");
        var selectItems = document.getElementById("select-items");
        var selectOptions = selectItems.querySelectorAll("li");

        selectSelected.addEventListener("click", () => {
          selectItems.classList.toggle("show");
          var expanded = selectSelected.getAttribute("aria-expanded") === "true";
          selectSelected.setAttribute("aria-expanded", (!expanded).toString());
        });

        selectOptions.forEach((item) => {
          item.addEventListener("click", () => {
            const langMap = {};selectedLang.textContent = item.textContent;
            selectItems.classList.remove("show");
            selectOptions.forEach((option) => {
              option.classList.remove("selected");
            });
            item.classList.add("selected");
            if (item.dataset.value === 'zh-cn') {
              return;
            }
            if (!langMap[item.dataset.value]) {
              _$("#lang-tooltip").style.opacity = "1";
              setTimeout(() => {
                _$("#lang-tooltip").style.opacity = "0";
              }, 1000);
              return;
            }
            window.location = langMap[item.dataset.value];
          });
        });

        document.addEventListener("click", (event) => {
          if (!event.target.closest(".custom-dropdown")) {
            selectItems.classList.remove("show");
            selectSelected.setAttribute("aria-expanded", "false");
          }
        });
      </script>
    </nav></div>
<header id="header" aria-label="Site header"><picture></picture><img crossorigin="anonymous" fetchpriority="high" src="/images/banner1.webp" alt="线性代数——代码实现"><div id="header-outer">
    <div id="header-title"><span id="logo">
            <h1 data-aos="slide-up">线性代数——代码实现</h1>
          </span><h2 id="subtitle-wrap" data-aos="slide-down"></h2></div>
  </div>
</header><div id="content"
          aria-label="Page content"
          
          class="sidebar-left"  ><aside id="sidebar" aria-label="Sidebar"><div class="sidebar-wrapper-container sticky"><div class="sidebar-wrapper">
    <div
      class="sidebar-wrap"
      data-aos="fade-up"
    ><div class="sidebar-toc-sidebar"><h3 class="toc-title">文章目录</h3>
<div class="sidebar-toc-wrapper toc-div-class">
  <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#链接">链接</a></li>
        <li><a href="#需要导入的库">需要导入的库</a></li>
      </ul>
    </li>
  </ul>
</nav>
</div></div>
          <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img
    data-src="/avatar/avatar1.webp"
    data-sizes="auto"
    alt="落-luo"
    class="lazyload"
  />
  <div class="sidebar-author-name">落-luo</div>
  <div class="sidebar-description">少女祈祷中...</div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>文章</div><div class="sidebar-state-number">33</div>
  </div>
  <a class="sidebar-state-category" href="/categories/" aria-label="sidebar-state-category-link">
    <div>分类</div>
    <div class="sidebar-state-number">
      7
    </div>
  </a>
  <a class="sidebar-state-tag" href="/tags/" aria-label="sidebar-state-tag-link">
    <div>标签</div>
    <div class="sidebar-state-number">21</div>
  </a>
</div>
<div class="sidebar-social"><div class="icon-github sidebar-social-icon">
      <a
        href="https://github.com/l-luoluo"
        itemprop="url"
        target="_blank"
        aria-label="github"
        rel="noopener nofollow noreferrer"
      ></a>
    </div></div>
<div class="sidebar-menu"><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/"
        aria-label="首页"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">首页</div>
    </div><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/archives"
        aria-label="归档"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">归档</div>
    </div><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/about"
        aria-label="关于"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">关于</div>
    </div><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/friend"
        aria-label="友链"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">友链</div>
    </div></div></div><div class="sidebar-btn-wrapper" style="position:static">
            <div class="sidebar-toc-btn current"></div>
            <div class="sidebar-common-btn"></div>
          </div></div>
  </div><div class="sidebar-widget"></div></div></aside>
<section id="main" aria-label="Main content"><article
  class="h-entry article"
  itemscope
  itemtype="https://schema.org/BlogPosting"
>
  <div
    class="article-inner"
    data-aos="fade-up"
  >
    <div class="article-meta"><div class="article-date">
  <span
    class="article-date-link icon-calendar"
    data-aos="zoom-in"
  >
    <time datetime="2025-11-18 15:00:00 &#43;0800 CST" itemprop="datePublished"
      >2025-11-18</time
    >
    <time style="display: none;" id="post-update-time"
      >2025-11-18</time
    >
  </span></div>
<div class="article-category"><a
      class="article-category-link"
      href="/categories/%e8%b7%9f%e7%9d%80%e6%9d%8e%e6%b2%90%e5%ad%a6ai"
      data-aos="zoom-in"
      >跟着李沐学AI</a
    ><a
      class="article-category-link"
      href="/categories/%e5%8a%a8%e6%89%8b%e5%ad%a6%e6%b7%b1%e5%ba%a6%e5%ad%a6v2"
      data-aos="zoom-in"
      >动手学深度学V2</a
    ></div>
</div><div class="hr-line"></div><div class="e-content article-entry" itemprop="articleBody"><h3 id="链接">
<a class="header-anchor" href="#%e9%93%be%e6%8e%a5"></a>
链接
</h3><p><a href="https://courses.d2l.ai/zh-v2/assets/notebooks/chapter_preliminaries/linear-algebra.slides.html#/">线性代数</a></p>
<h3 id="需要导入的库">
<a class="header-anchor" href="#%e9%9c%80%e8%a6%81%e5%af%bc%e5%85%a5%e7%9a%84%e5%ba%93"></a>
需要导入的库
</h3><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span></code></pre></div><h4 id="1标量">
<a class="header-anchor" href="#1%e6%a0%87%e9%87%8f"></a>
1.标量
</h4><p>标量由只有一个元素的张量表示</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">/</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="n">y</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))
</span></span></code></pre></div><h4 id="2向量">
<a class="header-anchor" href="#2%e5%90%91%e9%87%8f"></a>
2.向量
</h4><p>可以将向量视为标量值组成的列表</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([0, 1, 2, 3])
</span></span></code></pre></div><h5 id="21-访问向量的元素">
<a class="header-anchor" href="#21-%e8%ae%bf%e9%97%ae%e5%90%91%e9%87%8f%e7%9a%84%e5%85%83%e7%b4%a0"></a>
2.1 访问向量的元素
</h5><p>可以通过张量的索引来访问任一元素</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor(3)
</span></span></code></pre></div><h5 id="22-向量的长度">
<a class="header-anchor" href="#22-%e5%90%91%e9%87%8f%e7%9a%84%e9%95%bf%e5%ba%a6"></a>
2.2 向量的长度
</h5><p>向量的长度是元素的数量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">4
</span></span></code></pre></div><h5 id="23-只有一个轴的张量形状只有一个元素">
<a class="header-anchor" href="#23-%e5%8f%aa%e6%9c%89%e4%b8%80%e4%b8%aa%e8%bd%b4%e7%9a%84%e5%bc%a0%e9%87%8f%e5%bd%a2%e7%8a%b6%e5%8f%aa%e6%9c%89%e4%b8%80%e4%b8%aa%e5%85%83%e7%b4%a0"></a>
2.3 只有一个轴的张量，形状只有一个元素
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">torch.Size([4])
</span></span></code></pre></div><h4 id="3矩阵">
<a class="header-anchor" href="#3%e7%9f%a9%e9%98%b5"></a>
3.矩阵
</h4><p>通过指定两个分量m和 n来创建一个形状为m×n的矩阵</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[ 0,  1,  2,  3],
</span></span><span class="line"><span class="cl">        [ 4,  5,  6,  7],
</span></span><span class="line"><span class="cl">        [ 8,  9, 10, 11],
</span></span><span class="line"><span class="cl">        [12, 13, 14, 15],
</span></span><span class="line"><span class="cl">        [16, 17, 18, 19]])
</span></span></code></pre></div><h5 id="31-矩阵的转置">
<a class="header-anchor" href="#31-%e7%9f%a9%e9%98%b5%e7%9a%84%e8%bd%ac%e7%bd%ae"></a>
3.1 矩阵的转置
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[ 0,  4,  8, 12, 16],
</span></span><span class="line"><span class="cl">        [ 1,  5,  9, 13, 17],
</span></span><span class="line"><span class="cl">        [ 2,  6, 10, 14, 18],
</span></span><span class="line"><span class="cl">        [ 3,  7, 11, 15, 19]])
</span></span></code></pre></div><h5 id="32-对称矩阵">
<a class="header-anchor" href="#32-%e5%af%b9%e7%a7%b0%e7%9f%a9%e9%98%b5"></a>
3.2 对称矩阵
</h5><p>对称矩阵（symmetric matrix）A
等于其转置：A=A⊤</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[1, 2, 3],
</span></span><span class="line"><span class="cl">        [2, 0, 4],
</span></span><span class="line"><span class="cl">        [3, 4, 5]])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">B</span> <span class="o">==</span> <span class="n">B</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[True, True, True],
</span></span><span class="line"><span class="cl">        [True, True, True],
</span></span><span class="line"><span class="cl">        [True, True, True]])
</span></span></code></pre></div><h4 id="4数据结构">
<a class="header-anchor" href="#4%e6%95%b0%e6%8d%ae%e7%bb%93%e6%9e%84"></a>
4.数据结构
</h4><p>就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[[ 0,  1,  2,  3],
</span></span><span class="line"><span class="cl">         [ 4,  5,  6,  7],
</span></span><span class="line"><span class="cl">         [ 8,  9, 10, 11]],
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        [[12, 13, 14, 15],
</span></span><span class="line"><span class="cl">         [16, 17, 18, 19],
</span></span><span class="line"><span class="cl">         [20, 21, 22, 23]]])
</span></span></code></pre></div><h4 id="41">
<a class="header-anchor" href="#41"></a>
4.1
</h4><p>给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">B</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">A</span> <span class="o">+</span> <span class="n">B</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor([[ 0.,  1.,  2.,  3.],
</span></span><span class="line"><span class="cl">         [ 4.,  5.,  6.,  7.],
</span></span><span class="line"><span class="cl">         [ 8.,  9., 10., 11.],
</span></span><span class="line"><span class="cl">         [12., 13., 14., 15.],
</span></span><span class="line"><span class="cl">         [16., 17., 18., 19.]]),
</span></span><span class="line"><span class="cl"> tensor([[ 0.,  2.,  4.,  6.],
</span></span><span class="line"><span class="cl">         [ 8., 10., 12., 14.],
</span></span><span class="line"><span class="cl">         [16., 18., 20., 22.],
</span></span><span class="line"><span class="cl">         [24., 26., 28., 30.],
</span></span><span class="line"><span class="cl">         [32., 34., 36., 38.]]))
</span></span></code></pre></div><h4 id="42-哈达玛积">
<a class="header-anchor" href="#42-%e5%93%88%e8%be%be%e7%8e%9b%e7%a7%af"></a>
4.2 哈达玛积
</h4><p>两个矩阵的按元素乘法称为哈达玛积（Hadamard product）（数学符号⊙
）</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">B</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[  0.,   1.,   4.,   9.],
</span></span><span class="line"><span class="cl">        [ 16.,  25.,  36.,  49.],
</span></span><span class="line"><span class="cl">        [ 64.,  81., 100., 121.],
</span></span><span class="line"><span class="cl">        [144., 169., 196., 225.],
</span></span><span class="line"><span class="cl">        [256., 289., 324., 361.]])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">a</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">a</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor([[[ 2,  3,  4,  5],
</span></span><span class="line"><span class="cl">          [ 6,  7,  8,  9],
</span></span><span class="line"><span class="cl">          [10, 11, 12, 13]],
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">         [[14, 15, 16, 17],
</span></span><span class="line"><span class="cl">          [18, 19, 20, 21],
</span></span><span class="line"><span class="cl">          [22, 23, 24, 25]]]),
</span></span><span class="line"><span class="cl"> torch.Size([2, 3, 4]))
</span></span></code></pre></div><h5 id="421-计算其元素的和">
<a class="header-anchor" href="#421-%e8%ae%a1%e7%ae%97%e5%85%b6%e5%85%83%e7%b4%a0%e7%9a%84%e5%92%8c"></a>
4.2.1 计算其元素的和
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor([0., 1., 2., 3.]), tensor(6.))
</span></span></code></pre></div><h5 id="422-计算矩阵的元素的和">
<a class="header-anchor" href="#422-%e8%ae%a1%e7%ae%97%e7%9f%a9%e9%98%b5%e7%9a%84%e5%85%83%e7%b4%a0%e7%9a%84%e5%92%8c"></a>
4.2.2 计算矩阵的元素的和
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(torch.Size([5, 4]), tensor(190.))
</span></span></code></pre></div><h4 id="5指定张量沿哪一个轴来通过求和降低维度">
<a class="header-anchor" href="#5%e6%8c%87%e5%ae%9a%e5%bc%a0%e9%87%8f%e6%b2%bf%e5%93%aa%e4%b8%80%e4%b8%aa%e8%bd%b4%e6%9d%a5%e9%80%9a%e8%bf%87%e6%b1%82%e5%92%8c%e9%99%8d%e4%bd%8e%e7%bb%b4%e5%ba%a6"></a>
5.指定张量沿哪一个轴来通过求和降低维度
</h4><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A_sum_axis0</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A_sum_axis0</span><span class="p">,</span> <span class="n">A_sum_axis0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">A_sum_axis1</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A_sum_axis1</span><span class="p">,</span> <span class="n">A_sum_axis1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor([40., 45., 50., 55.]), torch.Size([4]))
</span></span><span class="line"><span class="cl">(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))
</span></span><span class="line"><span class="cl">tensor(190.)
</span></span></code></pre></div><h4 id="6-计算平均值">
<a class="header-anchor" href="#6-%e8%ae%a1%e7%ae%97%e5%b9%b3%e5%9d%87%e5%80%bc"></a>
6. 计算平均值
</h4><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">A</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor(9.5000), tensor(9.5000))
</span></span><span class="line"><span class="cl">(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))
</span></span></code></pre></div><h5 id="61-计算轴上的平均值保持轴数不变">
<a class="header-anchor" href="#61-%e8%ae%a1%e7%ae%97%e8%bd%b4%e4%b8%8a%e7%9a%84%e5%b9%b3%e5%9d%87%e5%80%bc%e4%bf%9d%e6%8c%81%e8%bd%b4%e6%95%b0%e4%b8%8d%e5%8f%98"></a>
6.1 计算轴上的平均值（保持轴数不变）
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sum_A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">sum_A</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[ 6.],
</span></span><span class="line"><span class="cl">        [22.],
</span></span><span class="line"><span class="cl">        [38.],
</span></span><span class="line"><span class="cl">        [54.],
</span></span><span class="line"><span class="cl">        [70.]])
</span></span></code></pre></div><h5 id="62通过广播将a除以sum_a得到矩阵a的行平均值">
<a class="header-anchor" href="#62%e9%80%9a%e8%bf%87%e5%b9%bf%e6%92%ad%e5%b0%86a%e9%99%a4%e4%bb%a5sum_a%e5%be%97%e5%88%b0%e7%9f%a9%e9%98%b5a%e7%9a%84%e8%a1%8c%e5%b9%b3%e5%9d%87%e5%80%bc"></a>
6.2通过广播将A除以sum_A得到矩阵A的行平均值
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span> <span class="o">/</span> <span class="n">sum_A</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[0.0000, 0.1667, 0.3333, 0.5000],
</span></span><span class="line"><span class="cl">        [0.1818, 0.2273, 0.2727, 0.3182],
</span></span><span class="line"><span class="cl">        [0.2105, 0.2368, 0.2632, 0.2895],
</span></span><span class="line"><span class="cl">        [0.2222, 0.2407, 0.2593, 0.2778],
</span></span><span class="line"><span class="cl">        [0.2286, 0.2429, 0.2571, 0.2714]])
</span></span></code></pre></div><h5 id="63-某个轴计算a元素的累积总和">
<a class="header-anchor" href="#63-%e6%9f%90%e4%b8%aa%e8%bd%b4%e8%ae%a1%e7%ae%97a%e5%85%83%e7%b4%a0%e7%9a%84%e7%b4%af%e7%a7%af%e6%80%bb%e5%92%8c"></a>
6.3 某个轴计算A元素的累积总和
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[ 0,  1,  2,  3],
</span></span><span class="line"><span class="cl">        [ 4,  6,  8, 10],
</span></span><span class="line"><span class="cl">        [12, 15, 18, 21],
</span></span><span class="line"><span class="cl">        [24, 28, 32, 36],
</span></span><span class="line"><span class="cl">        [40, 45, 50, 55]])
</span></span></code></pre></div><h4 id="7-点积">
<a class="header-anchor" href="#7-%e7%82%b9%e7%a7%af"></a>
7. 点积
</h4><p>点积是相同位置的按元素乘积的和</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))
</span></span></code></pre></div><h5 id="71">
<a class="header-anchor" href="#71"></a>
7.1
</h5><p>我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor(6.)
</span></span></code></pre></div><h6 id="72-矩阵向量积ax">
<a class="header-anchor" href="#72-%e7%9f%a9%e9%98%b5%e5%90%91%e9%87%8f%e7%a7%afax"></a>
7.2 矩阵向量积Ax
</h6><p>矩阵向量积Ax是一个长度为m的列向量，其第i个元素是点积a⊤ix</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))
</span></span></code></pre></div><h5 id="73-矩阵-矩阵乘法">
<a class="header-anchor" href="#73-%e7%9f%a9%e9%98%b5-%e7%9f%a9%e9%98%b5%e4%b9%98%e6%b3%95"></a>
7.3 矩阵-矩阵乘法
</h5><p>我们可以将矩阵-矩阵乘法AB看作是简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n×m矩阵</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor([[ 6.,  6.,  6.],
</span></span><span class="line"><span class="cl">        [22., 22., 22.],
</span></span><span class="line"><span class="cl">        [38., 38., 38.],
</span></span><span class="line"><span class="cl">        [54., 54., 54.],
</span></span><span class="line"><span class="cl">        [70., 70., 70.]])
</span></span></code></pre></div><h4 id="8l2范数">
<a class="header-anchor" href="#8l2%e8%8c%83%e6%95%b0"></a>
8.L2范数
</h4><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor(5.)
</span></span></code></pre></div><h5 id="81l1范数">
<a class="header-anchor" href="#81l1%e8%8c%83%e6%95%b0"></a>
8.1.L1范数
</h5><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor(7.)
</span></span></code></pre></div><h5 id="82-矩阵的frobenius范数">
<a class="header-anchor" href="#82-%e7%9f%a9%e9%98%b5%e7%9a%84frobenius%e8%8c%83%e6%95%b0"></a>
8.2 矩阵的Frobenius范数
</h5><p>矩阵的Frobenius范数（Frobenius norm）是矩阵元素平方和的平方根</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">))))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">tensor(6.)
</span></span></code></pre></div></div>
    <footer class="article-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item" data-aos="zoom-in">
      <a
        class="article-tag-list-link"
        href="/tags/%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0"
        rel="tag"
        >线性代数</a
      >
    </li><li class="article-tag-list-item" data-aos="zoom-in">
      <a
        class="article-tag-list-link"
        href="/tags/%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0"
        rel="tag"
        >代码实现</a
      >
    </li></ul>
</footer>
  </div><nav
    id="article-nav"
    aria-label="Article navigation"
    data-aos="fade-up"
  ><div class="article-nav-link-wrap left"><img
              data-src="https://d-sketon.top/img/_backwebp/bg1.webp"
              data-sizes="auto"
              alt="线性代数"
              class="lazyload"
            /><a
          href="/post/no.25/"
          aria-label="前一篇:线性代数"
          title="前一篇:线性代数"
        ></a>
        <div class="article-nav-caption">前一篇</div>
        <h3 class="article-nav-title">线性代数</h3>
      </div><div class="article-nav-link-wrap right"><img
              data-src="https://d-sketon.top/img/_backwebp/bg1.webp"
              data-sizes="auto"
              alt="矩阵计算"
              class="lazyload"
            /><a
          href="/post/no.27/"
          aria-label="后一篇:矩阵计算"
          title="后一篇:矩阵计算"
        ></a>
        <div class="article-nav-caption">后一篇</div>
        <h3 class="article-nav-title">矩阵计算</h3>
      </div></nav></article><section id="comments" data-aos="fade-up">
<div class="comment-header"><h2 class="comment-title">说些什么吧！</h2>
  <div class="comment-selector">
    <div class="comment-selector-wrap"><div class="selector-item" data-selector="giscus">
          <span>giscus</span>
        </div></div>
  </div>
</div>

<div class="comment-content"><div class="comment giscus-comment" data-aos="fade-up"
     >
    </div></div>
</section></section>
        </div><footer id="footer" aria-label="Site footer">
  <div style="width: 100%; overflow: hidden">
    <div class="footer-line"></div>
  </div>
  <div id="footer-info"><div>
      <span class="icon-copyright"></span>2025<span class="footer-info-sep rotate"></span>
      落-luo
    </div><div>
        基于&nbsp;<a
          href="https://gohugo.io/"
          target="_blank"
          rel="noopener nofollow noreferrer"
          >Hugo</a
        >&nbsp; Theme.<a
          href="https://github.com/D-Sketon/hugo-theme-reimu"
          target="_blank"
          rel="noopener nofollow noreferrer"
          >Reimu</a
        >
      </div><div>
        <span class="icon-brush"
          >&nbsp;24.2k</span
        >
        &nbsp;|&nbsp;
        <span class="icon-coffee">&nbsp;01:05</span>
      </div><div>
        <span class="icon-eye"></span>
        <span id="busuanzi_container_site_pv"
          >总访问量&nbsp;<span
            id="busuanzi_value_site_pv"
          ></span
        ></span>
        &nbsp;|&nbsp;
        <span class="icon-user"></span>
        <span id="busuanzi_container_site_uv"
          >总访客量&nbsp;<span
            id="busuanzi_value_site_uv"
          ></span
        ></span>
      </div></div>
</footer>
<div class="sidebar-top">
            <div class="sidebar-top-taichi rotate"></div>
            <div class="arrow-up"></div>
          </div><div id="mask" class="hide"></div>
      </div><nav id="mobile-nav" aria-label="Mobile navigation">
  <div class="sidebar-wrap"><div class="sidebar-toc-sidebar"><h3 class="toc-title">文章目录</h3>
<div class="sidebar-toc-wrapper toc-div-class">
  <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#链接">链接</a></li>
        <li><a href="#需要导入的库">需要导入的库</a></li>
      </ul>
    </li>
  </ul>
</nav>
</div></div>
        <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img
    data-src="/avatar/avatar1.webp"
    data-sizes="auto"
    alt="落-luo"
    class="lazyload"
  />
  <div class="sidebar-author-name">落-luo</div>
  <div class="sidebar-description">少女祈祷中...</div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>文章</div><div class="sidebar-state-number">33</div>
  </div>
  <a class="sidebar-state-category" href="/categories/" aria-label="sidebar-state-category-link">
    <div>分类</div>
    <div class="sidebar-state-number">
      7
    </div>
  </a>
  <a class="sidebar-state-tag" href="/tags/" aria-label="sidebar-state-tag-link">
    <div>标签</div>
    <div class="sidebar-state-number">21</div>
  </a>
</div>
<div class="sidebar-social"><div class="icon-github sidebar-social-icon">
      <a
        href="https://github.com/l-luoluo"
        itemprop="url"
        target="_blank"
        aria-label="github"
        rel="noopener nofollow noreferrer"
      ></a>
    </div></div>
<div class="sidebar-menu"><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/"
        aria-label="首页"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">首页</div>
    </div><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/archives"
        aria-label="归档"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">归档</div>
    </div><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/about"
        aria-label="关于"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">关于</div>
    </div><div class="sidebar-menu-link-wrap">
      <a
        class="sidebar-menu-link-dummy"
        href="/friend"
        aria-label="友链"
      ></a>
      <div class='sidebar-menu-icon icon rotate'>&#xe62b;</div>
      <div class="sidebar-menu-link">友链</div>
    </div></div></div></div><div class="sidebar-btn-wrapper">
        <div class="sidebar-toc-btn current"></div>
        <div class="sidebar-common-btn"></div>
      </div></nav>
</div><script
    src="https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js"
    integrity="sha384-3gT/vsepWkfz/ff7PpWNUeMzeWoH3cDhm/A8jM7ouoAK0/fP/9bcHHR5kHq2nf&#43;e" crossorigin="anonymous"></script><script
    src="https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js"
    integrity="sha384-J08i8An/QeARD9ExYpvphB8BsyOj3Gh2TSh1aLINKO3L0cMSH2dN3E22zFoXEi0Q" crossorigin="anonymous"></script><script
    src="https://npm.webcache.cn/material-theme@1.0.0/dist/material-theme.umd.js"
    integrity="sha384-vLev0II0HKFaxkcm&#43;/7kX5IGwVFBASkGchU311wmU/veIj2bB0UcBkQbW6yw2asK" crossorigin="anonymous"></script><script src="/js/main.js" ></script><script src="/js/aos.js" ></script><script>
    var aosInit = () => {
      AOS.init({
        duration: 1000,
        easing: "ease",
        once: true,
        offset: 50,
      });
    };
    if (document.readyState === "loading") {
      document.addEventListener("DOMContentLoaded", aosInit);
    } else {
      aosInit();
    }
  </script><script src="/js/pjax_main.js" data-pjax></script><script
    src="https://npm.webcache.cn/mouse-firework@0.1.1/dist/index.umd.js"
    integrity="sha384-8LyaidD9GPxQQgLJO/WRw/O2h3BoNq/ApI/ecpvM6RsrCz2qP2ppBXUKihP4V/2d" crossorigin="anonymous"></script><script>
  if (! false  || !window.matchMedia('(max-width: 768px)').matches) {
    if (window.firework) {
      const options = JSON.parse("{\"excludeelements\":[\"a\",\"button\"],\"particles\":[{\"colors\":[\"var(--red-1)\",\"var(--red-2)\",\"var(--red-3)\",\"var(--red-4)\"],\"duration\":[1200,1800],\"easing\":\"easeOutExpo\",\"move\":[\"emit\"],\"number\":20,\"shape\":\"circle\",\"shapeOptions\":{\"alpha\":[0.3,0.5],\"radius\":[16,32]}},{\"colors\":[\"var(--red-0)\"],\"duration\":[1200,1800],\"easing\":\"easeOutExpo\",\"move\":[\"diffuse\"],\"number\":1,\"shape\":\"circle\",\"shapeOptions\":{\"alpha\":[0.2,0.5],\"lineWidth\":6,\"radius\":20}}]}");
      options.excludeElements = options.excludeelements;
      delete options.excludeelements;
      window.firework(options);
    }
  }
</script>

<div id="lazy-script">
  <div><script data-pjax>
        window.REIMU_POST = {
          author: "落-luo",
          title: "线性代数——代码实现",
          url: "http:\/\/localhost:1313\/post\/no.26\/",
          description: "文中所有所用资料均来自：动手学深度学V2",
          cover: "http:\/\/localhost:1313\/images\/banner1.webp",
        };
      </script><script src="/js/insert_highlight.js" data-pjax></script><script type="module" data-pjax>const PhotoSwipeLightbox = (await safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe-lightbox.esm.min.js", "sha384-DiL6M\/gG\u002bwmTxmCRZyD1zee6lIhawn5TGvED0FOh7fXcN9B0aZ9dexSF\/N6lrZi\/")).default;const initPswp = (gallery, children) => {
          if (_$$(`${gallery} ${children}`).length > 0) {
            new PhotoSwipeLightbox({
              gallery,
              children,pswpModule: () => safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8\u002boTJ7m3DfYEWX1fu1scuS4\u002bs")}).init();
          }
        }
        const pswp = () => {
          initPswp('.article-entry', 'a.article-gallery-item');
          initPswp('.article-gallery', 'a.article-gallery-item');
          window.lightboxStatus = 'done';
          window.removeEventListener('lightbox:ready', pswp);
        }
        if(window.lightboxStatus === 'ready') {
          pswp()
        } else {
          window.addEventListener('lightbox:ready', pswp);
        }
      </script><script data-pjax>
  var loadScript = (src, integrity) => {
    const script = document.createElement('script');
    script.src = src;
    if (integrity) script.integrity = integrity;
    script.crossOrigin = 'anonymous';
    return script;
  };
  var commentConfigKeys = ['valine', 'waline', 'twikoo', 'gitalk', 'giscus'];
  var commentConfig = {giscus: {
      enable: true,
      load: () => {
        const container = document.querySelector('.giscus-comment');
        if (!container) return;
        container.style.display = 'block';

        
        const existingScript = container.querySelector('script[src*="giscus.app/client.js"]');
        if (existingScript) existingScript.remove();
        const existingFrame = document.querySelector('iframe.giscus-frame');
        if (existingFrame) existingFrame.remove();

        
        const giscusScript = document.createElement('script');
        const domMode = document.documentElement.getAttribute("data-theme");

        const docLang = document.documentElement.lang || 'en';
        const langBase = docLang.split('-')[0];
        const supportedLangs = ['ar', 'be', 'bg', 'ca', 'cs', 'da', 'de', 'en', 
        'eo', 'es', 'eu', 'fa', 'fr', 'gr', 'hbs', 'he', 'hu', 'id', 'it', 'ja', 
        'kh', 'ko', 'nl', 'pl', 'pt', 'ro', 'ru', 'th', 'tr', 'uk', 'uz', 'vi', 'zh-CN', 'zh-HK', 'zh-TW'];
        const giscusLang = supportedLangs.includes(docLang) ? docLang : supportedLangs.includes(langBase) ? langBase : 'en';

        giscusScript.src = 'https://giscus.app/client.js';
        giscusScript.setAttribute('data-repo', 'l-luoluo\/l-luoluo.github.io');
        giscusScript.setAttribute('data-repo-id', 'R_kgDOQOU67w');
        giscusScript.setAttribute('data-category', 'Announcements');
        giscusScript.setAttribute('data-category-id', 'DIC_kwDOQOU6784CyE2X');
        giscusScript.setAttribute('data-mapping', '0');
        giscusScript.setAttribute('data-strict', '0');
        giscusScript.setAttribute('data-reactions-enabled', '1');
        giscusScript.setAttribute('data-emit-metadata', '0');
        giscusScript.setAttribute('data-input-position', 'bottom');
        giscusScript.setAttribute('data-theme', domMode === 'dark' ? 'dark' : 'light');
        giscusScript.setAttribute('data-lang', giscusLang);
        giscusScript.setAttribute('crossorigin', 'anonymous');
        giscusScript.async = true;
        container.appendChild(giscusScript);
        document.body.addEventListener('light-theme-set', () => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: { setConfig: { theme: 'light' } } }, 'https://giscus.app');
        });
        document.body.addEventListener('dark-theme-set', () => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: { setConfig: { theme: 'dark' } } }, 'https://giscus.app');
        });
      }
    }};
  commentConfig.enable = commentConfigKeys.some(key => commentConfig?.[key]?.enable);

  var defaultComment = '';
  if (commentConfig.enable) {
    
    var savedCommentType = localStorage.getItem('commentType');
    
    
    if (savedCommentType) {
      if (commentConfig[savedCommentType]?.enable) {
        defaultComment = savedCommentType;
      }
    }
    
    
    if (!defaultComment) {
      var configDefault = 'waline';
      if (commentConfig[configDefault]?.enable) {
        defaultComment = configDefault;
      }
    }
    
    
    if (!defaultComment) {
      defaultComment = commentConfigKeys.find(sys => commentConfig?.[sys]?.enable) || '';
    }
  }

  function loadComments() {
    if (!commentConfig.enable) return;
    
    const loadedComments = {
      valine: false,
      waline: false,
      twikoo: false,
      gitalk: false,
      giscus: false
    };

    
    const hideAllComments = () => {
      const commentContainers = document.querySelectorAll('.comment');
      commentContainers.forEach(container => {
        container.style.display = 'none';
      });
    };

    
    const loadCommentSystem = (type) => {
      if (loadedComments[type]) {
        
        document.querySelector(`.${type}-comment`).style.display = 'block';
        return;
      }

      
      commentConfig[type]?.load();
      loadedComments[type] = true;
    };

    
    const changeActiveCommentItems = (item) => {
      const commentItems = document.querySelectorAll('.selector-item');
      for (let i = 0; i < commentItems.length; i++) {
        commentItems[i].classList.remove('active');
      }
      item.classList.add('active');

      
      const commentType = item.getAttribute('data-selector');

      
      hideAllComments();

      
      loadCommentSystem(commentType);
    };

    const commentInit = () => {
      
      const commentItems = document.querySelectorAll('.selector-item');
      for (let item of commentItems) {
        item.addEventListener('click', () => {
          
          const commentType = item.getAttribute('data-selector');
          window.localStorage.setItem('commentType', commentType);
          
          changeActiveCommentItems(item);
        });
      }

      
      if (defaultComment) {
        const defaultSelectorItem = document.querySelector(`[data-selector="${defaultComment}"]`);
        if (!defaultSelectorItem) return;
        defaultSelectorItem.style.display = 'block';
        defaultSelectorItem.classList.add('active');
        loadCommentSystem(defaultComment);
      }
    }

    if (document.readyState === 'loading') {
      document.addEventListener('DOMContentLoaded', commentInit);
    } else {
      commentInit();
    }
  };
  loadComments();
</script><script
    src="https://npm.webcache.cn/katex@0.16.24/dist/katex.min.js"
    data-pjaxintegrity="sha384-MWNUH0WmtsYGhn2cbH6ELRCbf9LG3QDqCC&#43;gqPB3IBNO35xjZK3Ejb6oONRpDbPg" crossorigin="anonymous"></script><script
    src="https://npm.webcache.cn/katex@0.16.24/dist/contrib/auto-render.min.js"
    data-pjaxintegrity="sha384-hCXGrW6PitJEwbkoStFjeJxv&#43;fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"></script><script data-pjax>
          var renderMath = () => {
            if (!window.renderMathInElement) return;
            window.renderMathInElement(_$("article"), {
              delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "\\[", right: "\\]", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
              ],
            });
          };
          if (document.readyState === "loading") {
            document.addEventListener("DOMContentLoaded", renderMath, { once: true });
          } else {
            renderMath();
          }
        </script></div>
</div><script
    src="https://npm.webcache.cn/busuanzi@2.3.0/bsz.pure.mini.js"
    asyncintegrity="sha384-0M75wtSkhjIInv4coYlaJU83&#43;OypaRCIq2SukQVQX04eGTCBXJDuWAbJet56id&#43;S" crossorigin="anonymous"></script><script>
    if ('serviceWorker' in navigator) {
      navigator.serviceWorker.getRegistrations().then((registrations) => {
        for (let registration of registrations) {
          registration.unregister();
        }
      });
    }
  </script><script>
  const reimuCopyright = String.raw`
   ______     ______     __     __    __     __  __    
  /\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
  \ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
   \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
    \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                    
  `;
  console.log(String.raw`%c ${reimuCopyright}`, "color: #ff5252;");
  console.log(
    "%c Theme.Reimu" + " %c https://github.com/D-Sketon/hugo-theme-reimu ",
    "color: white; background: #ff5252; padding:5px 0;",
    "padding:4px;border:1px solid #ff5252;",
  );
</script><script src="/sakura.js"></script></body>
</html>
