[
  {
    "objectID": "6deef711245f0d4afb1ecf618cca29dc50486a62",
    "permalink": "/post/no.34/",
    "title": "softmax回归","content": "\r链接\rsoftmax回归\n1.softmax回归诞生\rsoftmax回归是一种用于多分类问题的线性模型。 在实际应用中，我们通常会遇到多分类问题，例如识别图像中的物体、分类文本等。 但线性回归只能处理二分类问题，不能直接处理多分类问题。 因此，我们需要创造出一个新的模型，能够处理多分类问题。 softmax回归就是为了解决这个问题而诞生的。 它的基本思想是将每个类别的输出转换为一个概率值，然后选择概率最高的类别作为预测结果。 其本质还是一个线性模型，只是在输出层添加了一个softmax函数，将线性输出转换为概率分布。 2.softmax回归的损失函数\rsoftmax回归使用均方损失函数来衡量预测值与真实值之间的差异。 均方损失函数的定义如下： $$\rL(y, \\hat{y}) = \\frac{1}{2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\r$$ 其中，$y$ 是真实值，$\\hat{y}$ 是预测值，$n$ 是样本数量。 均方损失函数的目标是最小化预测值与真实值之间的差异，从而提高模型的预测准确性。 3.softmax回归的无校验损失\rsoftmax回归的损失函数是一个无校验损失函数，这意味着它不考虑预测值与真实值之间的差异是否大于某个阈值。 这在多分类问题中是合理的，因为我们通常不关心预测值与真实值之间的差异是否大于某个阈值，而只关心预测结果是否正确。 例如，在图像分类问题中，我们只关心图像被分类为哪个类别，而不关心分类的准确性。 因此，softmax回归的损失函数是一个无校验损失函数，它只考虑预测结果是否正确，而不考虑预测值与真实值之间的差异。 4.softmax回归的有校验损失\rsoftmax回归的损失函数还可以考虑预测值与真实值之间的差异是否大于某个阈值。 这在某些应用场景中是必要的，例如在医疗诊断中，我们需要考虑预测值与真实值之间的差异是否大于某个阈值，以判断是否需要进一步的检查。 因此，softmax回归的损失函数还可以考虑预测值与真实值之间的差异是否大于某个阈值，这被称为有校验损失函数。 有校验损失函数的定义如下： $$\rL(y, \\hat{y}) = \\sum_{i=1}^n \\mathbb{I}(y_i \\neq \\hat{y}_i)\r$$ 其中，$y$ 是真实值，$\\hat{y}$ 是预测值，$n$ 是样本数 …","date": "2025-11-23 15:00:00",
    "updated": "2025-11-23 15:00:00"
  }, 
  {
    "objectID": "b92f81f9d5e5f1ae86ced6ce78b838fe4fe7da33",
    "permalink": "/post/no.35/",
    "title": "softmax回归——代码实现","content": "\r链接\rsoftmax回归代码实现 代码实现\r1.导入必要的库\rimport torch from IPython import display from d2l import torch as d2l 2.读取数据集\rbatch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) 3.初始化模型参数\r# 初始化模型参数 num_inputs = 784 num_outputs = 10 # 初始化权重矩阵W和偏置向量b W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True) b = torch.zeros(num_outputs, requires_grad=True) 4.定义softmax操作\rdef softmax(X): # 对每个样本的每个输出进行指数化 X_exp = torch.exp(X) # 对每个样本的指数化输出进行归一化 partition = X_exp.sum(1, keepdim=True) # 每个样本的softmax概率分布 return X_exp / partition 5.定义模型\rdef net(X): # 输入层到输出层的线性变换 return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) 6.定义损失函数\r# 定义交叉熵损失函数 def cross_entropy(y_hat, y): return -torch.log(y_hat[range(len(y_hat)), y]) 7.计算正确预测的数量\rdef accuracy(y_hat, y): # 计算预测正确的数量 if len(y_hat.shape) \u0026amp;gt; 1 and y_hat.shape[1] \u0026amp;gt; 1: y_hat = y_hat.argmax(axis=1) cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum()) 8.计算模型在数据集上的准确率\rdef evaluate_accuracy(net, …","date": "2025-11-23 15:00:00",
    "updated": "2025-11-23 15:00:00"
  }, 
  {
    "objectID": "cbc9b46badc652a40c66ee25a459e305918fb44b",
    "permalink": "/post/no.33/",
    "title": "线性回归的代码实现","content": "\r链接\r线性回归的代码实现\n代码实现\r1.导入所需的库\rimport torch from torch import nn from d2l import torch as d2l 2.生成数据集\rdef synthetic_data(w, b, num_examples): #生成 y = Xw + b + 噪声。 # w: 权重向量 # b: 偏置项 # num_examples: 样本数量 # 返回值: # X: 特征矩阵，形状为 (num_examples, len(w)) # y: 标签向量，形状为 (num_examples, 1) X = torch.normal(0, 1, (num_examples, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) # 生成数据集 true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) 3.读取数据集\r# 读取数据集 def data_iter(batch_size, features, labels): # 随机打乱数据集 num_examples = len(features) # 随机打乱索引 indices = list(range(num_examples)) random.shuffle(indices) # 从打乱后的索引中提取批次数据 for i in range(0, num_examples, batch_size): batch_indices = torch.tensor(indices[i:min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] # 定义批量大小 batch_size = 10 # 遍历数据集 for X, y in data_iter(batch_size, features, labels): print(X, \u0026#39;\\n\u0026#39;, y) break 4.初始化模型参数\r# 初始化模型参数 w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True) b = torch.zeros(1, requires_grad=True) 5.定义模型\r# 定义模型 def linreg(X, w, b): return torch.matmul(X, w) + b 6.定义损失函数\r# 定义损失函数 def squared_loss(y_hat, y): return (y_hat - y.reshape(y_hat.shape))**2 / 2 7.定义优化算法\r# 定义优化算法 def sgd(params, lr, batch_size): with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_() 8.训练模型\r# 训练模型 lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) l.sum().backward() sgd([w, b], lr, batch_size) with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) 9.评估模型\r# 评估模型 print(f\u0026#39;w的估计误差: {true_w - w.reshape(true_w.shape)}\u0026#39;) print(f\u0026#39;b的估计误差: {true_b - b}\u0026#39;) 完整代码\rimport torch from torch import nn from d2l import torch as d2l import random # 生成数据集 true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = d2l.synthetic_data(true_w, true_b, 1000) # 读取数据集 def data_iter(batch_size, features, labels): # 随机打乱数据集 num_examples = len(features) # 随机打乱索引 indices = list(range(num_examples)) random.shuffle(indices) # 从打乱后的索引中提取批次数据 for i in range(0, num_examples, batch_size): batch_indices = torch.tensor(indices[i:min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] # 定义批量大小 batch_size = 10 # 遍历数据集 for X, y in data_iter(batch_size, features, labels): print(X, \u0026#39;\\n\u0026#39;, y) break # 初始化模型参数 w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True) b = torch.zeros(1, requires_grad=True) # 定义模型 def linreg(X, w, b): return torch.matmul(X, w) + b # 定义损失函数 def squared_loss(y_hat, y): return (y_hat - y.reshape(y_hat.shape))**2 / 2 # 定义优化算法 def sgd(params, lr, batch_size): with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_() # 训练模型 lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) l.sum().backward() sgd([w, b], lr, batch_size) with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) # 评估模型 print(f\u0026#39;w的估计误差: {true_w - w.reshape(true_w.shape)}\u0026#39;) print(f\u0026#39;b的估计误差: {true_b - b}\u0026#39;) ","date": "2025-11-22 15:00:00",
    "updated": "2025-11-22 15:00:00"
  }, 
  {
    "objectID": "d4c60d3ed841dff37e7469da7d9bfaa520d74c2c",
    "permalink": "/post/no.32/",
    "title": "基础优化方法","content": "\r链接\r基础优化方法\n1.梯度下降\r梯度下降是一种优化算法，用于最小化损失函数。它的基本思想是通过迭代更新参数，使损失函数达到最小值。\n梯度下降的更新规则如下： $$\r\\theta := \\theta - \\eta \\nabla L(\\theta)\r$$ 其中，$\\theta$ 是参数向量，$\\eta$ 是学习率，$\\nabla L(\\theta)$ 是损失函数 $L(\\theta)$ 对参数 $\\theta$ 的梯度。\n2.学习率\r学习率是梯度下降算法中的一个超参数，用于控制每次参数更新的步长。 学习率的选择对梯度下降算法的性能有重要影响。 如果学习率 too small，那么算法收敛速度会很慢； 如果学习率 too large，那么算法可能会发散，无法收敛。 所以在选择学习率时，需要权衡这两个因素。\n3.小批量梯度下降\r批量梯度下降是一种梯度下降算法，用于最小化损失函数。 它的基本思想是在每次迭代中，使用所有训练样本计算损失函数的梯度，并根据梯度更新参数。\n批量梯度下降的更新规则如下： $$\r\\theta := \\theta - \\eta \\frac{1}{m} \\sum_{i=1}^m \\nabla L(\\theta; x_i, y_i)\r$$ 其中，$m$ 是训练样本的数量，$x_i$ 是第 $i$ 个样本的特征向量，$y_i$ 是第 $i$ 个样本的标签。\n4.选择批量大小\r批量大小是小批量梯度下降算法中的一个超参数，用于控制每次迭代中使用的训练样本数量。 批量大小的选择对小批量梯度下降算法的性能有重要影响。 如果批量大小 too small，那么算法收敛速度会很慢； 如果批量大小 too large，那么算法可能会内存不足，无法运行。 所以在选择批量大小时，需要权衡这两个因素。\n5.总结\r","date": "2025-11-21 15:00:00",
    "updated": "2025-11-21 15:00:00"
  }, 
  {
    "objectID": "dac6b9409c05646924f9c577a4857a442190b1a7",
    "permalink": "/post/no.30/",
    "title": "线性回归","content": "\r链接\r线性回归\n线性模型\r损失函数\r为了衡量模型的预测值与真实值之间的差异，我们引入了损失函数。 损失函数是一个标量值，用于衡量模型的预测值与真实值之间的差异。\n训练数据\r在训练线性模型时，我们需要使用训练数据来拟合模型的参数。 训练数据是一个包含输入特征和对应输出标签的数据集。 每个样本都是一个特征向量和一个标量标签。\n参数更新\r在训练过程中，我们需要根据损失函数来更新模型的参数。 更新参数的基本思想是：根据损失函数的梯度，朝着损失函数减小的方向更新参数。\n显示解\r总结\r","date": "2025-11-20 15:00:00",
    "updated": "2025-11-20 15:00:00"
  }, 
  {
    "objectID": "0eef2ad1e163e3281057df427d1faaa60624f449",
    "permalink": "/post/no.31/",
    "title": "线性回归-代码","content": "\r链接\r线性回归\n代码实现\r1.\rimport math import time import numpy as np import torch from d2l import torch as d2l 2.\rn = 10000 a = torch.ones(n) b = torch.ones(n) 3.\rclass Timer: #记录多次运行时间 def __init__(self): self.times = [] self.start() def start(self): #启动计时器 self.tik = time.time() def stop(self): #停止计时器并将时间记录在列表中 self.times.append(time.time() - self.tik) return self.times[-1] def avg(self): #返回平均时间 return sum(self.times) / len(self.times) def sum(self): #返回时间总和 return sum(self.times) def cumsum(self): #返回累计时间 return np.array(self.times).cumsum().tolist() 4.\r# 我们使用for循环，每次执行一位的加法 c = torch.zeros(n) timer = Timer() for i in range(n): c[i] = a[i] + b[i] f\u0026#39;{timer.stop():.5f} sec\u0026#39; \u0026#39;0.11435 sec\u0026#39; 第二种方法\n# 我们可以使用运算符+来执行按元素加法 timer.start() d = a + b f\u0026#39;{timer.stop():.5f} sec\u0026#39; \u0026#39;0.00052 sec\u0026#39; 5.\r# 定义一个函数来计算正态分布 def normal(x, mu, sigma): p = 1 / math.sqrt(2 * math.pi * sigma**2) return p * np.exp(-0.5 / sigma**2 * (x - mu)**2) 6.\r# 可视化正态分布 x = np.arange(-7, 7, 0.01) # 均值和标准差对 params = [(0, 1), (0, 2), (3, 1)] d2l.plot(x, [normal(x, mu, sigma) for mu, sigma in params], xlabel=\u0026#39;x\u0026#39;, ylabel=\u0026#39;p(x)\u0026#39;, figsize=(4.5, 2.5), legend=[f\u0026#39;mean {mu}, std {sigma}\u0026#39; for mu, sigma in params]) ","date": "2025-11-20 15:00:00",
    "updated": "2025-11-20 15:00:00"
  }, 
  {
    "objectID": "f69744aca9550a1bcc9aabe931ca91c8d986d210",
    "permalink": "/post/no.28/",
    "title": "自动求导","content": "\r链接\r自动求导\n1. 向量的链式法则\r向量的链式法则是标量的链式法则在向量上的推广。 它的基本思想是：如果一个函数 $f$ 是向量的函数，而 $g$ 是标量的函数，那么 $f$ 对 $g$ 的导数就是 $f$ 对每个元素的导数与 $g$ 对每个元素的导数的点积。\n2.自动求导\r自动求导是指通过计算图来自动计算函数的导数。 它的基本思想是：将函数表示为一个计算图，其中将代码分解成操作子，计算表示为无环图。\n2.1. 正向传播\r正向传播是指从输入层开始，按照计算图的顺序，一层一层地计算，直到输出层。 在正向传播过程中，我们会计算每个节点的输出值，并将其存储在节点中。\n2.2. 反向传播\r反向传播是指从输出层开始，按照计算图的逆序，一层一层地计算，直到输入层。 在反向传播过程中，我们会计算每个节点的梯度值，并将其存储在节点中。\n总结\r自动求导是指通过计算图来自动计算函数的导数。 它的基本思想是：将函数表示为一个计算图，其中将代码分解成操作子，计算表示为无环图。 在正向传播过程中，我们会计算每个节点的输出值，并将其存储在节点中。 而反向传播去除掉了正向传播中计算的中间值，只保留了输出值和梯度值。 减少了内存占用，同时也减少了计算量。\n","date": "2025-11-19 15:00:00",
    "updated": "2025-11-19 15:00:00"
  }, 
  {
    "objectID": "55318032095586526a54a56abe0eb5a9990acde6",
    "permalink": "/post/no.29/",
    "title": "自动求导-代码","content": "\r链接\r自动求导-代码\n代码实现\r假设我们想对函数$y=2x⊤x$关于列向量$x$求导\n1.\rimport torch x = torch.arange(4.0) # 定义一个x，为4维向量 print(x) tensor([0., 1., 2., 3.]) 2.\rx.requires_grad_(True) # 开启x的梯度计算 print(x.grad) # 查看x的梯度 3.\ry = 2 * torch.dot(x, x) # 计算y print(y) tensor(28., grad_fn=\u0026lt;MulBackward0\u0026gt;) 4.\ry.backward() # 对y进行反向传播 print(x.grad) # 查看x的梯度 x == 4 * x # 验证x的梯度是否正确 tensor([ 0., 4., 8., 12.]) tensor([True, True, True, True]) 5.\r# 计算另外一个x x.grad.zero_() # 清空x的梯度 y = x.sum() y.backward() print(x.grad) tensor([1., 1., 1., 1.]) 6.\rx.grad.zero_() y = x * x y.sum().backward() print(x.grad) tensor([0., 2., 4., 6.]) ","date": "2025-11-19 15:00:00",
    "updated": "2025-11-19 15:00:00"
  }, 
  {
    "objectID": "d69b40a81651f8b3907fa8f6e1d3662d092d89ec",
    "permalink": "/post/no.27/",
    "title": "矩阵计算","content": "\r链接\r矩阵计算\n1. 标量导数\r标量函数的导数是一个标量，它是切线的斜率，用于表示函数在某个点的变化率。\n2.亚导数\r亚导数是指在某个点上函数的导数不存在时，我们可以用一个小于导数的量来代替导数，这个量就叫做亚导数。 也就是将导数拓展到不可微的函数\n3.梯度\r梯度是指函数在某个点上的导数向量，它表示函数在该点上的变化方向和速率。 在多元函数中，梯度是一个向量，它的每个元素都是函数在该点上对该变量的导数。 也就是将导数拓展到向量中\n3.1 梯度的计算\r梯度的计算是指计算函数在某个点上的梯度向量。 它可以通过对函数的每个变量分别求导来得到。 例如，对于函数 $f(x, y) = x^2 + y^2$，它的梯度向量为 $\\nabla f = (2x, 2y)$。\n4.矩阵导数\r矩阵导数是指函数在某个点上的导数矩阵，它表示函数在该点上的变化方向和速率。 在多元函数中，矩阵导数是一个矩阵，它的每个元素都是函数在该点上对该变量的导数。 也就是将导数拓展到矩阵中\n","date": "2025-11-18 15:00:00",
    "updated": "2025-11-18 15:00:00"
  }, 
  {
    "objectID": "8be84f1df80cb6d048a5e79091809909141f9c01",
    "permalink": "/post/no.26/",
    "title": "线性代数——代码实现","content": "\r链接\r线性代数\n需要导入的库\rimport torch 1.标量\r标量由只有一个元素的张量表示\nx = torch.tensor([3.0]) y = torch.tensor([2.0]) print(x + y, x * y, x / y, x**y) (tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.])) 2.向量\r可以将向量视为标量值组成的列表\nx = torch.arange(4) print(x) tensor([0, 1, 2, 3]) 2.1 访问向量的元素\r可以通过张量的索引来访问任一元素\nprint(x[3]) tensor(3) 2.2 向量的长度\r向量的长度是元素的数量\nprint(len(x)) 4 2.3 只有一个轴的张量，形状只有一个元素\rprint(x.shape) torch.Size([4]) 3.矩阵\r通过指定两个分量m和 n来创建一个形状为m×n的矩阵\nA = torch.arange(20).reshape(5, 4) print(A) tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]) 3.1 矩阵的转置\rprint(A.T) tensor([[ 0, 4, 8, 12, 16], [ 1, 5, 9, 13, 17], [ 2, 6, 10, 14, 18], [ 3, 7, 11, 15, 19]]) 3.2 对称矩阵\r对称矩阵（symmetric matrix）A 等于其转置：A=A⊤\nB = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) print(B) tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) print(B == B.T) tensor([[True, True, True], [True, True, True], [True, True, True]]) 4.数据结构\r就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构\nX = torch.arange(24).reshape(2, 3, 4) …","date": "2025-11-18 15:00:00",
    "updated": "2025-11-18 15:00:00"
  }, 
  {
    "objectID": "fcbe0ba0f4c91b82d28e0d7a4e99fbf7c28a98ea",
    "permalink": "/post/no.25/",
    "title": "线性代数","content": "\r链接\r线性代数\n线性代数\r1. 标量与简单运算\r标量是一个只有大小没有方向的量。在数学中，标量通常用小写字母表示，例如 $a, b, c$ 等。\n2. 向量与简单运算\r向量是一个有序的量，它可以表示在空间中的一个点或方向。在数学中，向量通常用小写字母表示，例如 $x, y, z$ 等。 向量可以用箭头来表示，箭头的长度表示向量的大小，箭头的方向表示向量的方向。\n3. 矩阵与简单运算\r矩阵是一个二维数组，它可以表示多个向量的组合。在数学中，矩阵通常用大写字母表示，例如 $A, B, C$ 等。 矩阵可以用方括号来表示，例如 $A = \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\end{bmatrix}$ 表示一个 $2 \\times 3$ 的矩阵， 它包含了 $2$ 行 $3$ 列的元素。\n3.1 矩阵的乘法\r矩阵的乘法是一种将两个矩阵结合起来的操作，它可以用于表示线性变换。 既可以矩阵与向量的乘法，也可以矩阵与矩阵的乘法。 而矩阵的乘法也可以用于扭曲空间中的向量。\n3.2 范数\r范数是一种用于衡量向量大小的量，它可以用于表示向量的长度或距离。\n3.2 特殊矩阵\r特殊矩阵是指在某些特殊条件下出现的矩阵，它们在数学和工程中具有重要的应用。 例如，对称矩阵、正交矩阵、单位矩阵等都是特殊矩阵。\n","date": "2025-11-17 15:00:00",
    "updated": "2025-11-17 15:00:00"
  }, 
  {
    "objectID": "06248fd05eabd921417f0d4d6b9ed2a2eab40d7c",
    "permalink": "/post/no.24/",
    "title": "数据预处理","content": "\r链接\r数据预处理\n数据预处理\r1.创建一个简单的数据集\r2.加载数据集\r3.数据预处理\r为了处理缺失的数据，我们一般会使用以下方法：\n删除缺失值 填充缺失值（插值） 在实际应用中，我们通常会使用均值、中位数或众数来填充缺失值。 所以下面是一个使用均值填充缺失值的示例： 4.NAN值处理\r类别值和离散值通常会使用NAN值来表示缺失数据，所以我们需要注意在处理数据时不要将NAN值错误地解释为缺失值。 而是将NAN值作为一个独立的类别或离散值来处理。\n5.转化张量\r在深度学习中，我们通常会将数据转化为张量（Tensor）来进行计算。 而上面的输入和输出都是N维数组，所以我们可以直接将其转化为张量。\n","date": "2025-11-16 15:00:00",
    "updated": "2025-11-16 15:00:00"
  }, 
  {
    "objectID": "2dc150b1e11b5cdd72d9d9be21e0fdb4a4ce82e8",
    "permalink": "/post/no.23/",
    "title": "数据操作","content": "\r链接\r数据操作\nN维数组样例\r一般情况下，我们会使用N维数组来表示一个样本，其中N为样本的维度。 N=0代表着样本的数量，N=1代表着样本的特征维度，N=2代表着样本的特征矩阵维度。 N=3代表着样本的特征矩阵的维度，N=4代表着样本的特征矩阵的维度的维度，以此类推。\n创建数组\r访问数组元素\r数据操作\r1.导入必要的库\r2.张量\r张量可以表示一个数组，一个数组可能有多个维度 就像下面图片所示；他就是一个有12个元素的数组，每个元素都是一个标量（0维张量）。\n3.shape，numel属性\r张量的shape属性可以用来查看张量的形状，即每个维度的大小。 张量的numel属性可以用来查看张量的元素数量，即所有维度的大小的乘积。 就像下面图片所示:\n4.reshape方法\r张量的reshape方法可以用来改变张量的形状，而不改变张量的元素数量。 就像下面图片所示:\n5.全零张量，全一张量，从特定分布中随机采样\r张量的zeros方法可以用来创建一个全零张量，即所有元素都为0的张量。 张量的ones方法可以用来创建一个全一张量，即所有元素都为1的张量。 张量的rand方法可以用来从均匀分布中随机采样 就像下面图片所示:\n6.赋值操作\r可以通过python的赋值操作来改变张量的元素值。 就像下面图片所示:\n7.常见运算\r张量的常见运算包括加法、减法、乘法、除法、指数、对数、三角函数、矩阵乘法等。 就像下面图片所示:\n8.张量连结\r张量的连结操作可以用来将多个张量沿着指定的维度连结起来。 就像下面图片所示:\n9.通过逻辑符构建二维张量\r张量的逻辑运算符可以用来构建一个二维张量，其中每个元素都是一个逻辑值（True或False）。 就像下面图片所示:\n10.张量求和\r张量的sum方法可以用来对张量的元素进行求和。 可以指定求和的维度，默认情况下对所有元素求和。 就像下面图片所示:\n11.广播机制\r广播机制是指在进行张量运算时，自动扩展张量的形状，以匹配运算的要求。 就像下面图片所示:\n12.选取元素\r张量的索引操作可以用来选取张量的元素。 可以使用方括号[]来指定索引，每个索引对应一个维度。 就像下面图片所示:\n13.写入元素\r可以通过索引操作来写入张量的元素。 就像下面图片所示:\n14.内存管理\r张量的内存管理包括张量的创建、销毁、复制等操作。 在进行张量运算时，需要注意张量的 …","date": "2025-11-15 15:00:00",
    "updated": "2025-11-15 15:00:00"
  }, 
  {
    "objectID": "e23d595b815eb641be3ddb1ea8476ec2bad4f545",
    "permalink": "/post/no.22./",
    "title": "ResNet模型搭建","content": "\r前言\r在前面的文章中有详细的训练代码和测试代码， 可以参考这两篇文章中的代码，只需要修改部分参数即可。\n搭建ResNet模型\r导入必要的库\rimport torch from torch import nn from torchsummary import summary 定义残差块\rclass Residual(nn.Module): def __init__(self, input_channels, num_channels, use_1conv=False, strides=1): super(Residual, self).__init__() self.ReLU = nn.ReLU() self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=num_channels, kernel_size=3, padding=1, stride=strides) self.conv2 = nn.Conv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=3, padding=1) self.bn1 = nn.BatchNorm2d(num_channels) self.bn2 = nn.BatchNorm2d(num_channels) if use_1conv: self.conv3 = nn.Conv2d(in_channels=input_channels, out_channels=num_channels, kernel_size=1, stride=strides) else: self.conv3 = None def forward(self, x): y = self.ReLU(self.bn1(self.conv1(x))) y = self.bn2(self.conv2(y)) if self.conv3: x = self.conv3(x) y = self.ReLU(y+x) return y 定义ResNet模型\rclass ResNet18(nn.Module): def __init__(self, Residual): super(ResNet18, self).__init__() self.b1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3), nn.ReLU(), nn.BatchNorm2d(64), nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) self.b2 = nn.Sequential(Residual(64, 64, use_1conv=False, strides=1), Residual(64, 64, use_1conv=False, strides=1)) self.b3 = nn.Sequential(Residual(64, 128, use_1conv=True, strides=2), Residual(128, 128, use_1conv=False, strides=1)) self.b4 = nn.Sequential(Residual(128, 256, use_1conv=True, strides=2), Residual(256, 256, use_1conv=False, strides=1)) self.b5 = nn.Sequential(Residual(256, 512, use_1conv=True, strides=2), Residual(512, 512, use_1conv=False, strides=1)) self.b6 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(512, 10)) 模型的前向传播\rdef forward(self, x): x = self.b1(x) x = self.b2(x) x = self.b3(x) x = self.b4(x) x = self.b5(x) x = self.b6(x) return x 模型的测试\rif __name__ == \u0026#34;__main__\u0026#34;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = ResNet18(Residual).to(device) print(summary(model, (1, 224, 224))) 完整代码\rimport torch from torch import nn from torchsummary import summary class Residual(nn.Module): def __init__(self, input_channels, num_channels, use_1conv=False, strides=1): super(Residual, self).__init__() self.ReLU = nn.ReLU() self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=num_channels, kernel_size=3, padding=1, stride=strides) self.conv2 = nn.Conv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=3, padding=1) self.bn1 = nn.BatchNorm2d(num_channels) self.bn2 = nn.BatchNorm2d(num_channels) if use_1conv: self.conv3 = nn.Conv2d(in_channels=input_channels, out_channels=num_channels, kernel_size=1, stride=strides) else: self.conv3 = None def forward(self, x): y = self.ReLU(self.bn1(self.conv1(x))) y = self.bn2(self.conv2(y)) if self.conv3: x = self.conv3(x) y = self.ReLU(y+x) return y class ResNet18(nn.Module): def __init__(self, Residual): super(ResNet18, self).__init__() self.b1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3), nn.ReLU(), nn.BatchNorm2d(64), nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) self.b2 = nn.Sequential(Residual(64, 64, use_1conv=False, strides=1), Residual(64, 64, use_1conv=False, strides=1)) self.b3 = nn.Sequential(Residual(64, 128, use_1conv=True, strides=2), Residual(128, 128, use_1conv=False, strides=1)) self.b4 = nn.Sequential(Residual(128, 256, use_1conv=True, strides=2), Residual(256, 256, use_1conv=False, strides=1)) self.b5 = nn.Sequential(Residual(256, 512, use_1conv=True, strides=2), Residual(512, 512, use_1conv=False, strides=1)) self.b6 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(512, 10)) def forward(self, x): x = self.b1(x) x = self.b2(x) x = self.b3(x) x = self.b4(x) x = self.b5(x) x = self.b6(x) return x if __name__ == \u0026#34;__main__\u0026#34;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = ResNet18(Residual).to(device) print(summary(model, (1, 224, 224))) ","date": "2025-11-14 15:00:00",
    "updated": "2025-11-14 15:00:00"
  }, 
  {
    "objectID": "dc059a5d6cf40286b56614690fc74fda029fcba4",
    "permalink": "/post/no.21/",
    "title": "ResNet模型原理","content": "\rResNet诞生背景\rResNet是2015年由微软的Kaiming He等人提出的，其主要目标是解决深度神经网络训练时的梯度消失问题。 同时，ResNet还提出了一种新的网络结构，即残差块（Residual Block），用于解决深度神经网络训练时的梯度消失问题。 后来，残差块被广泛应用于深度神经网络中，成为了一种非常重要的网络结构。\n残差块\r残差块的诞生原因\r在深度神经网络中，当网络层数增加时，梯度消失问题会变得更加严重。 这是因为在反向传播过程中，梯度会被不断地乘以权重矩阵，当权重矩阵的元素值比较小时，梯度会变得非常小，从而导致模型训练效果下降。 就在这样的情况下，凯明等人提出了残差块（Residual Block），用于解决深度神经网络训练时的梯度消失问题。\n残差块的结构\r残差块的结构非常简单，它包含了两个卷积层和一个跳跃连接（Shortcut Connection）。 在残差块中，第一个卷积层用于提取特征，第二个卷积层用于对特征进行变换。 而跳跃连接则用于将输入直接添加到输出中，从而实现了残差学习（Residual Learning）。\n残差块的详细网络参数\rBN层\r归一化的原因\rBatch Normalization（BN）层的主要作用是归一化输入数据，从而加速模型的训练过程。 在训练过程中，BN层会对每个小批量（mini-batch）的数据进行归一化，使得数据的均值为0，方差为1。 这样做的好处是可以使模型的训练更加稳定，从而提高模型的收敛速度。\nBN如何实现\rBN层的实现过程比较简单，主要包括以下几个步骤：\n对每个小批量（mini-batch）的数据进行归一化，计算每个特征的均值和方差。 对每个特征进行归一化，将其均值设为0，方差设为1。 对归一化后的数据进行缩放和偏移，即乘以一个缩放因子（scale factor）和加上一个偏移量（offset）。 BN层具体解决的问题\r总结\rResNet模型详细参数\r第一个残差块\r第二个残差块\r第三个残差块\r第四个残差块\r第五个残差块\r第六个残差块\r第七个残差块\r第八个残差块\r全连接层\r总结\rResNet模型中利用了残差块（Residual Block）来解决深度神经网络训练时的梯度消失问题。 其中BN层借助归一化操作，使得模型的训练更加稳定，从而提高模型的收敛速度。 同时BN层还加入了偏置项（bias），用于 …","date": "2025-11-14 15:00:00",
    "updated": "2025-11-14 15:00:00"
  }, 
  {
    "objectID": "ac146d62b3045e00e3259237d3cd8bba0a5b7a39",
    "permalink": "/post/no.20/",
    "title": "GoogleNet模型实践——水果分类","content": "\r前言\r这是GoogLeNet的另外一个模型实践，这次我们来做水果分类。 关于训练代码和测试代码，还有模型代码 请参考之前的文章。 这里就绪详细介绍一下模型的搭建过程，只是简单的介绍一下，需要修改的部分参数\n训练代码需要修改的参数\rROOT_TRAIN = r\u0026#39;data\\train\u0026#39; normalize = transforms.Normalize(mean=[0.22890568, 0.19639583, 0.1433638 ], std=[0.09950783, 0.07997292, 0.06596899]) 其中的ROOT_TRAIN是训练集的路径，需要根据自己的数据集路径修改。normalize中的mean和std是根据训练集的图片通过数据集的处理 进行计算得到的，需要根据自己的数据集修改。\n测试代码需要修改的参数\r1.\rROOT_TRAIN = r\u0026#39;data\\train\u0026#39; normalize = transforms.Normalize(mean=[0.22890568, 0.19639583, 0.1433638 ], std=[0.09950783, 0.07997292, 0.06596899]) 将上述代码的修改复制粘贴到测试代码中即可。\n2.\rclasses = [\u0026#39;猫\u0026#39;, \u0026#39;狗\u0026#39;] # with torch.no_grad(): # for b_x, b_y in test_dataloader: # b_x = b_x.to(device) # b_y = b_y.to(device) # # # 设置模型为验证模型 # model.eval() # output = model(b_x) # pre_lab = torch.argmax(output, dim=1) # result = pre_lab.item() # label = b_y.item() # print(\u0026#34;预测值：\u0026#34;, classes[result], \u0026#34;------\u0026#34;, \u0026#34;真实值：\u0026#34;, classes[label]) 只需要将classes修改为\nclasses = [\u0026#39;苹果\u0026#39;,\u0026#39;香蕉\u0026#39;,\u0026#39;葡萄\u0026#39;, \u0026#39;橙子\u0026#39;, \u0026#39;梨\u0026#39;] 关于代码中注释掉的部分，是用来打印每个测试样本的预测值和真实值的，如果需要的话，可以先将其下的代码注释掉，然后将这部分代码取消注释即可。\n","date": "2025-11-13 15:00:00",
    "updated": "2025-11-13 15:00:00"
  }, 
  {
    "objectID": "d4ae64683d5f53ce5bd7177892263577a48c29bd",
    "permalink": "/post/no.17/",
    "title": "GoogleNet模型实践——猫狗分类.1","content": "\r前言\r这篇文章主要介绍如何使用GoogleNet模型对自己的数据集进行猫狗分类前期准备工作， 详细的训练代码在下一篇文章中介绍\n数据集准备\r划分数据集\rimport os from shutil import copy import random def mkfile(file): if not os.path.exists(file): os.makedirs(file) # 获取data文件夹下所有文件夹名（即需要分类的类名） file_path = \u0026#39;data_cat_dog\u0026#39; flower_class = [cla for cla in os.listdir(file_path)] # 创建 训练集train 文件夹，并由类名在其目录下创建5个子目录 mkfile(\u0026#39;data/train\u0026#39;) for cla in flower_class: mkfile(\u0026#39;data/train/\u0026#39; + cla) # 创建 验证集val 文件夹，并由类名在其目录下创建子目录 mkfile(\u0026#39;data/test\u0026#39;) for cla in flower_class: mkfile(\u0026#39;data/test/\u0026#39; + cla) # 划分比例，训练集 : 测试集 = 9 : 1 split_rate = 0.1 # 遍历所有类别的全部图像并按比例分成训练集和验证集 for cla in flower_class: cla_path = file_path + \u0026#39;/\u0026#39; + cla + \u0026#39;/\u0026#39; # 某一类别的子目录 images = os.listdir(cla_path) # iamges 列表存储了该目录下所有图像的名称 num = len(images) eval_index = random.sample(images, k=int(num * split_rate)) # 从images列表中随机抽取 k 个图像名称 for index, image in enumerate(images): # eval_index 中保存验证集val的图像名称 if image in eval_index: image_path = cla_path + image new_path = \u0026#39;data/test/\u0026#39; + cla copy(image_path, new_path) # 将选中的图像复制到新路径 # 其余的图像保存在训练集train中 else: image_path = cla_path + image new_path = \u0026#39;data/train/\u0026#39; + cla copy(image_path, new_path) print(\u0026#34;\\r[{}] processing [{}/{}]\u0026#34;.format(cla, index + 1, num), end=\u0026#34;\u0026#34;) # processing bar print() print(\u0026#34;processing done!\u0026#34;) file_path:用于指定数据集的路径，需要修改为自己的数据集路径 split_rate:用于指定划分数据集的比例，默认值为0.1，即10%的数据用于验证集 data: 用于存放数据的目录 数据集的处理\rfrom PIL import Image import os import numpy as np # 文件夹路径，包含所有图片文件 folder_path = \u0026#39;data_cat_dog\u0026#39; # 初始化累积变量 total_pixels = 0 sum_normalized_pixel_values = np.zeros(3) # 如果是RGB图像，需要三个通道的均值和方差 # 遍历文件夹中的图片文件 for root, dirs, files in os.walk(folder_path): for filename in files: if filename.endswith((\u0026#39;.jpg\u0026#39;, \u0026#39;.jpeg\u0026#39;, \u0026#39;.png\u0026#39;, \u0026#39;.bmp\u0026#39;)): # 可根据实际情况添加其他格式 image_path = os.path.join(root, filename) image = Image.open(image_path) image_array = np.array(image) # 归一化像素值到0-1之间 normalized_image_array = image_array / 255.0 # print(image_path) # print(normalized_image_array.shape) # 累积归一化后的像素值和像素数量 total_pixels += normalized_image_array.size sum_normalized_pixel_values += np.sum(normalized_image_array, axis=(0, 1)) # 计算均值和方差 mean = sum_normalized_pixel_values / total_pixels sum_squared_diff = np.zeros(3) for root, dirs, files in os.walk(folder_path): for filename in files: if filename.endswith((\u0026#39;.jpg\u0026#39;, \u0026#39;.jpeg\u0026#39;, \u0026#39;.png\u0026#39;, \u0026#39;.bmp\u0026#39;)): image_path = os.path.join(root, filename) image = Image.open(image_path) image_array = np.array(image) # 归一化像素值到0-1之间 normalized_image_array = image_array / 255.0 # print(normalized_image_array.shape) # print(mean.shape) # print(image_path) try: diff = (normalized_image_array - mean) ** 2 sum_squared_diff += np.sum(diff, axis=(0, 1)) except: print(f\u0026#34;捕获到自定义异常\u0026#34;) # diff = (normalized_image_array - mean) ** 2 # sum_squared_diff += np.sum(diff, axis=(0, 1)) variance = sum_squared_diff / total_pixels print(\u0026#34;Mean:\u0026#34;, mean) print(\u0026#34;Variance:\u0026#34;, variance) 这给脚本主题要负责的是数据集的处理，包括归一化和计算均值方差 而这两个值在后续的模型训练中会被用到\n","date": "2025-11-12 15:00:00",
    "updated": "2025-11-12 15:00:00"
  }, 
  {
    "objectID": "aafd48144e4b2b4447348f7abbbc5d4416d59c7d",
    "permalink": "/post/no.18/",
    "title": "GoogleNet模型实践——猫狗分类.2","content": "\r前言\r这篇文章主要是关于猫狗分类的详细的训练代码,关于模型的代码可以参考GoogleNet模型搭建，其中有详细的代码\n训练代码\r1. 导入必要的库\rimport copy import time import torch from torchvision.datasets import ImageFolder from torchvision import transforms import torch.utils.data as Data import numpy as np import matplotlib.pyplot as plt from model import GoogLeNet,Inception import torch.nn as nn import pandas as pd 2. 数据预处理\r# 定义数据集路径 ROOT_TRAIN = r\u0026amp;#39;data\\train\u0026amp;#39; normalize = transforms.Normalize(mean=[0.162, 0.151, 0.138], std=[0.058, 0.052, 0.047]) # 定义数据集处理方法变量 train_transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),normalize]) # 加载数据集 train_data = ImageFolder(root=ROOT_TRAIN, transform=train_transform) train_data, val_data = Data.random_split(train_data, [round(0.8*len(train_data)), round(0.2*len(train_data))]) train_dataloader = Data.DataLoader(dataset=train_data, batch_size=64, shuffle=True, num_workers=4) val_dataloader = Data.DataLoader(dataset=val_data, batch_size=64, shuffle=True, num_workers=4) …","date": "2025-11-12 15:00:00",
    "updated": "2025-11-12 15:00:00"
  }, 
  {
    "objectID": "b42f88d5ce6bf12ae5672b7919396df1e05c4c58",
    "permalink": "/post/no.19/",
    "title": "GoogleNet模型实践——猫狗分类.3","content": "\r前言\r在之前的两篇文章中，我们分别介绍了GoogleNet数据集的准备和GoogleNet模型的搭建。 这篇文章主要是测试代码的搭建\n测试代码\r1. 导入必要的库\rimport torch import torch.utils.data as Data from torchvision import transforms from torchvision.datasets import ImageFolder from model import GoogLeNet,Inception from PIL import Image 2.数据集的预处理\r# 定义数据预处理 def test_data_process(): # 定义数据集路径 ROOT_TRAIN = r\u0026amp;#39;data\\test\u0026amp;#39; normalize = transforms.Normalize(mean=[0.162, 0.151, 0.138], std=[0.058, 0.052, 0.047]) # 定义数据集处理方法变量 test_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), normalize]) # 加载数据集 test_data = ImageFolder(root=ROOT_TRAIN, transform=test_transform) test_dataloader = Data.DataLoader(dataset=test_data, batch_size=1, shuffle=True, num_workers=0) return test_dataloader 3. 模型的测试代码\rdef test_model_process(model, test_dataloader): # 设定测试所用到的设备，有GPU用GPU没有GPU用CPU device = \u0026amp;#34;cuda\u0026amp;#34; if torch.cuda.is_available() else \u0026amp;#39;cpu\u0026amp;#39; # 讲模型放入到训练设备中 model = model.to(device) # 初始化参数 test_corrects = 0.0 test_num = 0 #  …","date": "2025-11-12 15:00:00",
    "updated": "2025-11-12 15:00:00"
  }, 
  {
    "objectID": "64d0ad85954400c90e6d7778b974302c437cd336",
    "permalink": "/post/no.16/",
    "title": "GoogleNet模型搭建","content": "\r前言\r关于训练代码，可以看之前LeNet-5模型的训练代码，GoogleNet模型的训练代码与LeNet模型的训练代码基本相同，只是模型不同。 详细的训练代码可以参考训练代码和测试代码。 文章链接中有详细的代码\n模型搭建\r1.导入必要的库\rimport torch from torch import nn from torchsummary import summary 2. Inception模块\rclass Inception(nn.Module): def __init__(self, in_channels,c1,c2,c3,c4): super(Inception, self).__init__() self.ReLU = nn.ReLU() # 路线1 1*1卷积 self.p1_1 = nn.Conv2d(in_channels=in_channels, out_channels=c1, kernel_size=1) # 路线二 1*1卷积 3*3卷积 self.p2_1 = nn.Conv2d(in_channels=in_channels, out_channels=c2[0], kernel_size=1) self.p2_2 = nn.Conv2d(in_channels=c2[0], out_channels=c2[1], kernel_size=3,padding=1) # 路线3 1*1卷积 5*5卷积 self.p3_1 = nn.Conv2d(in_channels=in_channels, out_channels=c3[0], kernel_size=1) self.p3_2 = nn.Conv2d(in_channels=c3[0], out_channels=c3[1], kernel_size=5, padding=2) # 路线4 3*3最大池化 1*1卷积 self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) self.p4_2 = nn.Conv2d(in_channels=in_channels, out_channels=c4, kernel_size=1) def forward(self, x): p1 = self.ReLU(self.p1_1(x)) p2 = self.ReLU(self.p2_2(self.ReLU(self.p2_1(x)))) p3 = self.ReLU(self.p3_2(self.ReLU(self.p3_1(x)))) p4 = self.ReLU(self.p4_2(self.p4_1(x))) return torch.cat([p1,p2,p3,p4], 1) 3. GoogleNet模型搭建\rclass GoogLeNet(nn.Module): def __init__(self,Inception): super(GoogLeNet,self).__init__() self.relu = nn.ReLU() self.b1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b2 = nn.Sequential( nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1), nn.ReLU(), nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b3 = nn.Sequential( Inception(192,64,[96,128],[16,32],32), Inception(256,128,[128,192],[32,96],64), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b4 = nn.Sequential( Inception(480,192,[96,208],[16,48],64), Inception(512,160,[112,224],[24,64],64), Inception(512,128,[128,256],[24,64],64), Inception(512,112,[128,288],[32,64],64), Inception(528,256,[160,320],[32,128],128), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b5 = nn.Sequential( Inception(832, 256, [160, 320], [32, 128], 128), Inception(832, 384, [192, 384], [48, 128], 128), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(1024,10), ) 4. 权重初始化\rfor m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;,nonlinearity=\u0026#39;relu\u0026#39;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m,nn.Linear): nn.init.normal_(m.weight,0,0.01) nn.init.constant_(m.bias, 0) 5.模型前向传播\rdef forward(self, x): x = self.b1(x) x = self.b2(x) x = self.b3(x) x = self.b4(x) x = self.b5(x) return x 6.模型测试\rif __name__ == \u0026#39;__main__\u0026#39;: device = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = GoogLeNet(Inception).to(device) print(summary(model,(1,224,224))) 完整代码展示\rimport torch from torch import nn from torchsummary import summary class Inception(nn.Module): def __init__(self, in_channels,c1,c2,c3,c4): super(Inception, self).__init__() self.ReLU = nn.ReLU() # 路线1 1*1卷积 self.p1_1 = nn.Conv2d(in_channels=in_channels, out_channels=c1, kernel_size=1) # 路线二 1*1卷积 3*3卷积 self.p2_1 = nn.Conv2d(in_channels=in_channels, out_channels=c2[0], kernel_size=1) self.p2_2 = nn.Conv2d(in_channels=c2[0], out_channels=c2[1], kernel_size=3,padding=1) # 路线3 1*1卷积 5*5卷积 self.p3_1 = nn.Conv2d(in_channels=in_channels, out_channels=c3[0], kernel_size=1) self.p3_2 = nn.Conv2d(in_channels=c3[0], out_channels=c3[1], kernel_size=5, padding=2) # 路线4 3*3最大池化 1*1卷积 self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1) self.p4_2 = nn.Conv2d(in_channels=in_channels, out_channels=c4, kernel_size=1) def forward(self, x): p1 = self.ReLU(self.p1_1(x)) p2 = self.ReLU(self.p2_2(self.ReLU(self.p2_1(x)))) p3 = self.ReLU(self.p3_2(self.ReLU(self.p3_1(x)))) p4 = self.ReLU(self.p4_2(self.p4_1(x))) return torch.cat([p1,p2,p3,p4], 1) class GoogLeNet(nn.Module): def __init__(self,Inception): super(GoogLeNet,self).__init__() self.relu = nn.ReLU() self.b1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b2 = nn.Sequential( nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1), nn.ReLU(), nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b3 = nn.Sequential( Inception(192,64,[96,128],[16,32],32), Inception(256,128,[128,192],[32,96],64), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b4 = nn.Sequential( Inception(480,192,[96,208],[16,48],64), Inception(512,160,[112,224],[24,64],64), Inception(512,128,[128,256],[24,64],64), Inception(512,112,[128,288],[32,64],64), Inception(528,256,[160,320],[32,128],128), nn.MaxPool2d(kernel_size=3, stride=2, padding=1), ) self.b5 = nn.Sequential( Inception(832, 256, [160, 320], [32, 128], 128), Inception(832, 384, [192, 384], [48, 128], 128), nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(1024,10), ) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=\u0026#39;fan_out\u0026#39;,nonlinearity=\u0026#39;relu\u0026#39;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m,nn.Linear): nn.init.normal_(m.weight,0,0.01) nn.init.constant_(m.bias, 0) def forward(self, x): x = self.b1(x) x = self.b2(x) x = self.b3(x) x = self.b4(x) x = self.b5(x) return x if __name__ == \u0026#39;__main__\u0026#39;: device = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = GoogLeNet(Inception).to(device) print(summary(model,(1,224,224))) 总结\rGoogLeNet模型的搭建其中最难的是Inception模块的搭建，Inception模块的搭建需要注意的是每个路线的卷积层的输出通道数，以及最后拼接的通道数。\n","date": "2025-11-11 15:00:00",
    "updated": "2025-11-11 15:00:00"
  }, 
  {
    "objectID": "21aa5fcb60becf15fbe5dceba48cc7c060c961d4",
    "permalink": "/post/no.15/",
    "title": "GoogleNet模型原理","content": "\rGoogleNet诞生背景\rGoogleNet的模型的诞生主要是为了解决卷积核大小的问题，早期的模型使用的卷积核大小都是比较大的，比如11x11、5x5等， 而为了验证卷积核大小对模型的影响，GoogleNet创新型的使用了多个不同大小的卷积核，比如1x1、3x3、5x5等， 让模型自己去选择合适的卷积核大小，去更新相关的参数，从而提高了模型的表达能力。 而这个创新型的设计，也使得GoogleNet的模型在当时的时间点上，成为了一个比较有代表性的模型。 这个块提出者将他命名为Inception块，因为这个块的设计灵感来自于电影《盗梦空间》中的场景， 其中主角在梦境中被一个inception结构的神经网络所干扰，导致他的梦境被改变。\nInception块结构\rInception块详细参数\r1*1卷积核的优点\r全局平均池化优缺点\r全局平均池化的优点\r全局平均池化的缺点\rGoogleNet详细参数\r第1个inception块详细参数\r第2个inception块详细参数\r第3个inception块详细参数\r第4个inception块详细参数\r第5个inception块详细参数\r第6个inception块详细参数\r第7个inception块详细参数\r第8个inception块详细参数\r第9个inception块详细参数\r全连接层参数\r总结\r关于1*1卷积核的优点，全局平均池化的优缺点可以观看炮哥的视频：1*1卷积的优点 这些东西有点抽象，不太好用文字来叙述出来，这也是大模型的一个缺点吧，就是解释起来比较困难，不太好理解。所以看不懂图中的东西，可以看看去炮哥的视频，说不定就能理解了\n","date": "2025-11-11 15:00:00",
    "updated": "2025-11-11 15:00:00"
  }, 
  {
    "objectID": "8240cf29e1706aa336a5ba901acdca2481ef29a2",
    "permalink": "/post/no.14/",
    "title": "VGG模型-模型搭建","content": "\r前言\r关于VGG模型的训练代码和测试代码可以参考LeNet-5模型的训练代码和测试代码，只是模型不同。 修改一下其中的一些参数就行\n模型搭建\r1.导入必要的库\rimport torch from torch import nn from torchsummary import summary 2.VGG模型搭建\rclass VGG16(nn.Module): def __init__(self): super(VGG16, self).__init__() self.block1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block2 = nn.Sequential( nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block3 = nn.Sequential( nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block4 = nn.Sequential( nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block5 = nn.Sequential( nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block6 = nn.Sequential( nn.Flatten(), nn.Linear(7*7*512, 256), nn.ReLU(), nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 10), ) 3.权重初始化\r# 权重初始化 for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, nonlinearity=\u0026#39;relu\u0026#39;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) if m.bias is not None: nn.init.constant_(m.bias, 0) 4.模型的前向传播\rdef forward(self, x): x = self.block1(x) x = self.block2(x) x = self.block3(x) x = self.block4(x) x = self.block5(x) x = self.block6(x) return x 5.模型的测试\rif __name__==\u0026#34;__main__\u0026#34;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = VGG16().to(device) print(summary(model, (1, 224, 224))) 完整代码展示\rimport torch from torch import nn from torchsummary import summary class VGG16(nn.Module): def __init__(self): super(VGG16, self).__init__() self.block1 = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block2 = nn.Sequential( nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block3 = nn.Sequential( nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block4 = nn.Sequential( nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block5 = nn.Sequential( nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2) ) self.block6 = nn.Sequential( nn.Flatten(), nn.Linear(7*7*512, 256), nn.ReLU(), nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 10), ) # 权重初始化 for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, nonlinearity=\u0026#39;relu\u0026#39;) if m.bias is not None: nn.init.constant_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.normal_(m.weight, 0, 0.01) if m.bias is not None: nn.init.constant_(m.bias, 0) def forward(self, x): x = self.block1(x) x = self.block2(x) x = self.block3(x) x = self.block4(x) x = self.block5(x) x = self.block6(x) return x if __name__==\u0026#34;__main__\u0026#34;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = VGG16().to(device) print(summary(model, (1, 224, 224))) 总结\rVGG模型的搭建与LeNet模型的搭建基本相同，只是VGG模型的卷积层更多，其余层的搭建与LeNet模型相同。 其中加入了一个权重初始化的函数，用于初始化模型的权重。 主要的目的是为了避免模型在训练过程中出现梯度消失或梯度爆炸的问题。 同时也可以提高模型的训练效率。 这里使用了Kaiming初始化方法，对卷积层的权重进行初始化。\n","date": "2025-11-10 15:00:00",
    "updated": "2025-11-10 15:00:00"
  }, 
  {
    "objectID": "8262b59feac9079cae55dab778b885eb44dcdfa2",
    "permalink": "/post/no.13/",
    "title": "VGG模型原理","content": "\rVGG诞生背景\rVGG的模型比AlexNet的更大，参数更多 在AlexNet的基础上，VGG提出了一种新的网络结构，即使用多个3x3的卷积核代替AlexNet中的11x11、5x5的卷积核，同时减少了参数数量。 由于3x3的卷积核可以覆盖更多的像素，因此VGG的模型在保持参数数量的同时，也提高了模型的表达能力。 卷积块的应用也使得VGG的模型可移植性比较好 本篇文章主要介绍VGG-16模型,也就是下面图中D的结构\nVGG-16模型结构\rVGG-16模型的结构与AlexNet的结构类似，都是由5个卷积块和3个全连接层组成。 每个卷积块由2个卷积层和1个池化层组成，卷积层的核大小都是3x3，步长都是1，填充都是1。 池化层的核大小都是2x2，步长都是2，填充都是0。 全连接层的节点数分别是4096、4096、1000。\n卷积块结构\rblock1详细参数\rblock2详细参数\rblock3详细参数\rblock4详细参数\rblock5详细参数\r总结\r","date": "2025-11-10 15:00:00",
    "updated": "2025-11-10 15:00:00"
  }, 
  {
    "objectID": "b06e69553386afbdaeae5fe774185c4c65b95658",
    "permalink": "/post/no.12/",
    "title": "AlexNet模型-模型代码搭建","content": "\r前言\r之后的文章只会介绍模型的代码搭建，而训练代码和测试代码 在链接里面有详细的代码，这里就不重复介绍了。\n模型代码搭建\r1. 导入所需的库\rimport torch from torch import nn from torchsummary import summary import torch.nn.functional as F 2. 模型搭建\rclass AlexNet(nn.Module): def __init__(self): super(AlexNet, self).__init__() self.ReLU = nn.ReLU() self.c1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4) self.s2 =nn.MaxPool2d(kernel_size=3, stride=2) self.c3 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1,padding=2) self.s4 = nn.MaxPool2d(kernel_size=3, stride=2) self.c5 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1) self.c6 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1) self.c7 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1) self.s8 = nn.MaxPool2d(kernel_size=3, stride=2) self.flatten = nn.Flatten() self.fc1 = nn.Linear(in_features=6*6*256, out_features=4096) self.fc2 = nn.Linear(in_features=4096, out_features=4096) self.fc3 = nn.Linear(in_features=4096, out_features=10) 其中c代表卷积层，s代表池化层，fc代表全连接层。\n3. 模型前向传播\rdef forward(self, x): x = self.ReLU(self.c1(x)) x = self.s2(x) x = self.ReLU(self.c3(x)) x = self.s4(x) x = self.ReLU(self.c5(x)) x = self.ReLU(self.c6(x)) x = self.ReLU(self.c7(x)) x = self.s8(x) x = self.flatten(x) x = self.ReLU(self.fc1(x)) x = F.dropout(x, p=0.5) x = self.ReLU(self.fc2(x)) x = F.dropout(x, p=0.5) x = self.fc3(x) return x 4. 模型测试代码\rif __name__ == \u0026#34;__main__\u0026#34;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = AlexNet().to(device) print(summary(model, (1, 227, 227))) 完整模型代码展示\rimport torch from torch import nn from torchsummary import summary import torch.nn.functional as F class AlexNet(nn.Module): def __init__(self): super(AlexNet, self).__init__() self.ReLU = nn.ReLU() self.c1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4) self.s2 =nn.MaxPool2d(kernel_size=3, stride=2) self.c3 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1,padding=2) self.s4 = nn.MaxPool2d(kernel_size=3, stride=2) self.c5 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1) self.c6 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1) self.c7 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1) self.s8 = nn.MaxPool2d(kernel_size=3, stride=2) self.flatten = nn.Flatten() self.fc1 = nn.Linear(in_features=6*6*256, out_features=4096) self.fc2 = nn.Linear(in_features=4096, out_features=4096) self.fc3 = nn.Linear(in_features=4096, out_features=10) def forward(self, x): x = self.ReLU(self.c1(x)) x = self.s2(x) x = self.ReLU(self.c3(x)) x = self.s4(x) x = self.ReLU(self.c5(x)) x = self.ReLU(self.c6(x)) x = self.ReLU(self.c7(x)) x = self.s8(x) x = self.flatten(x) x = self.ReLU(self.fc1(x)) x = F.dropout(x, p=0.5) x = self.ReLU(self.fc2(x)) x = F.dropout(x, p=0.5) x = self.fc3(x) return x if __name__ == \u0026#34;__main__\u0026#34;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = AlexNet().to(device) print(summary(model, (1, 227, 227))) ","date": "2025-11-09 15:00:00",
    "updated": "2025-11-09 15:00:00"
  }, 
  {
    "objectID": "5b1be64b913b9031a6b524df9344c8155b693d64",
    "permalink": "/post/no.10/",
    "title": "LeNet模型-测试代码搭建","content": "\r前言\r同样这一套的代码依旧是一套通用的代码，可以反复于其他模型的测试。\n测试代码搭建\r1. 导入必要的库\rimport torch import torch.utils.data as Data from torchvision import transforms from torchvision.datasets import FashionMNIST from model import LeNet 同样的，这里的模型文件也需要和测试代码在同一个目录下，并且要和模型文件的文件名一致。 可以参考\nfrom 你模型的文件名 import LeNet 2.数据处理\rdef test_data_process(): test_data = FashionMNIST(root=\u0026amp;#39;./data\u0026amp;#39;, train=False, transform=transforms.Compose([transforms.Resize(size=227), transforms.ToTensor()]), download=True) test_dataloader = Data.DataLoader(dataset=test_data, batch_size=1, shuffle=True, num_workers=0) return test_dataloader 3.模型测试代码\rdef test_model_process(model, test_dataloader): # 设定测试所用到的设备，有GPU用GPU没有GPU用CPU device = \u0026amp;#34;cuda\u0026amp;#34; if torch.cuda.is_available() else \u0026amp;#39;cpu\u0026amp;#39; # 讲模型放入到训练设备中 model = model.to(device) # 初始化参数 test_corrects = 0.0 test_num = 0 # 只进行前向传播计算，不计算梯度，从而节省内存，加快运行速度 with torch.no_grad(): for test_data_x, test_data_y in test_dataloader: # 将特征放入到测试设备中 test_data_x = test_data_x.to(device) # …","date": "2025-11-08 15:00:00",
    "updated": "2025-11-08 15:00:00"
  }, 
  {
    "objectID": "09bd8c18769cb0676c19e5e7589342a0c2bc6ce5",
    "permalink": "/post/no.11/",
    "title": "LeNet模型-模型代码搭建","content": "\r前言\r这篇文章主要为LeNet模型的代码搭建，代码主要参考了炮哥带你学的视频，但是我自己也添加了一些注释，希望可以帮助到大家。 代码运行的详细环境搭建可以参考炮哥的视频代码环境搭建\n模型代码搭建\r1. 导入必要的库\rimport torch from torch import nn from torchsummary import summary import torch.nn.functional as F 2. 搭建LeNet模型\rclass LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() self.c1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5,padding=2) self.sig = nn.Sigmoid() self.s2 = nn.AvgPool2d(kernel_size=2, stride=2) self.c3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5) self.s4 = nn.AvgPool2d(kernel_size=2, stride=2) self.flatten = nn.Flatten() self.f5 = nn.Linear(in_features=16*5*5, out_features=120) self.f6 = nn.Linear(in_features=120, out_features=84) self.f7 = nn.Linear(in_features=84, out_features=10) 其中c代表卷积层，s代表池化层，fc代表全连接层。\n3. 模型前向传播\rdef forward(self, x): x = self.sig(self.c1(x)) x = self.s2(x) x = self.sig(self.c3(x)) x = self.s4(x) x = self.flatten(x) x = self.f5(x) x = self.f6(x) x = self.f7(x) return x 4. 模型测试代码\rif __name__ == \u0026#39;__main__\u0026#39;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = LeNet().to(device) print(summary(model, (1, 28, 28))) 完整模型代码\rimport torch from torch import nn from torchsummary import summary class LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() self.c1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5,padding=2) self.sig = nn.Sigmoid() self.s2 = nn.AvgPool2d(kernel_size=2, stride=2) self.c3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5) self.s4 = nn.AvgPool2d(kernel_size=2, stride=2) self.flatten = nn.Flatten() self.f5 = nn.Linear(in_features=16*5*5, out_features=120) self.f6 = nn.Linear(in_features=120, out_features=84) self.f7 = nn.Linear(in_features=84, out_features=10) def forward(self, x): x = self.sig(self.c1(x)) x = self.s2(x) x = self.sig(self.c3(x)) x = self.s4(x) x = self.flatten(x) x = self.f5(x) x = self.f6(x) x = self.f7(x) return x if __name__ == \u0026#39;__main__\u0026#39;: device = torch.device(\u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) model = LeNet().to(device) print(summary(model, (1, 28, 28))) ","date": "2025-11-08 15:00:00",
    "updated": "2025-11-08 15:00:00"
  }, 
  {
    "objectID": "e40b2dcacce9614e71e176b88c4ce4ec40e43809",
    "permalink": "/post/no.9/",
    "title": "LeNet模型-训练代码搭建","content": "\r前言\r本片文章主要是通用的模型训练代码搭建，这个代码搭建完成后，我们就可以直接使用这个代码来训练我们的模型了。 而且后面的模型都可以复用这一套的代码，只需要修改一下模型的参数即可。\n代码搭建\r1.导入必要的库\r在这一步中，我们需要导入一些必要的库，这些库包括：\ncopy：用于复制对象 time：用于计算时间 torch：用于深度学习 torchvision：用于处理图像数据 numpy：用于数值计算 matplotlib：用于数据可视化 modle：用于导入模型 torch.nn：用于定义神经网络层 pandas：用于数据处理 import copy import time import torch from torchvision.datasets import FashionMNIST from torchvision import transforms import torch.utils.data as Data import numpy as np import matplotlib.pyplot as plt from model import LeNet import torch.nn as nn import pandas as pd 有关库的导入这里其中有一个库是model，这个是我们搭建模型时自己创建的一个文件，所以在引入的时候要和模型文件在同一个目录下，并且要和模型文件的文件名一致。 就像时我的模型文件是model.py，所以在引入的时候要写\nfrom model import LeNet 而你们的就是\nfrom 你模型的文件名 import LeNet 2. 数据处理\rdef train_val_data_process(): # 从FashionMNIST中导入训练数据，将数据转换为227*227的大小，同时将数据转换为tensor类型 train_data = FashionMNIST(root=\u0026amp;#39;./data\u0026amp;#39;, train=True, transform=transforms.Compose([transforms.Resize(size=227), transforms.ToTensor()]), download=True) # 划分训练集和验证集，训练集占80%，验证集占20% train_data, …","date": "2025-11-07 15:00:00",
    "updated": "2025-11-07 15:00:00"
  }, 
  {
    "objectID": "6e41b93accb5d6faf5456a18f36f45c2689f1da9",
    "permalink": "/post/no.8/",
    "title": "AlexNet原理","content": "\r1. 背景\rAlexNet 是 2012 年由 Alex Krizhevsky、Ilya Sutskever 和 Geoffrey Hinton 提出的卷积神经网络架构。它在 ImageNet 图像分类任务上取得了显著的成果，成为了卷积神经网络的一个重要里程碑。 它在当年的 ImageNet 图像分类任务上，取得第一名的成绩，也向世界证明了卷积神经网络在图像识别任务上要优于传统的机器学习算法。\n2. AlexNet 网络结构\r3. 网络参数详解\r4. Dropout 层\r为什么要加入 Dropout 层？\n其实是为了降低网络的参数，由于层数的增加，网络的参数也会增加，而 Dropout 层可以随机的将一些神经元的输出设为 0，从而减少网络的参数。 加快了网络的训练速度，同时也提高了网络的泛化能力。\n5. 图像增强\r5.1 水平翻转\r将图像左右翻转，增加数据集的多样性。\n5.2 随机裁剪\r从图像中随机裁剪出一个子区域，增加数据集的多样性。\n5.3 PCA\rPCA：主成分分析，将图像的像素值转换为主成分，从而减少图像的维度。\n5.4 LRN正则化\rLRN 正则化：局部响应归一化，对每个像素的响应进行归一化，从而提高模型的泛化能力。\n总的来说，图像增强技术可以增加数据集的多样性，提高模型的泛化能力。\n6. 总结\r","date": "2025-11-06 15:00:00",
    "updated": "2025-11-06 15:00:00"
  }, 
  {
    "objectID": "d5bdae485b1876705d0acd377b12e3d7d9cdd7e6",
    "permalink": "/post/no.7/",
    "title": "LeNet原理","content": "\r1. LeNet-5 诞生背景\rLenet-5 是 Yann LeCun 于 1998 年提出的卷积神经网络（Convolutional Neural Network，CNN）架构，用于识别手写数字。\n2. LeNet-5 网络结构\rLeNet-5 由 7 层组成，包括 2 个卷积层、2 个池化层、3 个全连接层。\nLeNet-5 后面的尾标5其实指的是它有2个卷积层，3个全连接层。池化层并不算在其中，包括后面的模型也是如此，尾标只包括卷积层和全连接层的数量。\n3. LeNet-5 网络层详解\r3.1 LeNet-5 网络参数详解\r4. 总结\r","date": "2025-11-06 14:00:00",
    "updated": "2025-11-06 14:00:00"
  }, 
  {
    "objectID": "60b6657f0eb1a28c32117a58cebecdae75db68c6",
    "permalink": "/post/no.6/",
    "title": "CNN卷积神经网络算法原理：第三章","content": "\r图片在计算机中的本质\r单色图片\r彩色图片\r其实从图片中我们可以看出，图片在计算机中的本质就是一个二维数组，每个元素就是一个像素点，每个像素点有三个通道，分别是RGB通道，每个通道的值范围是0-255，0表示该通道的亮度最低，255表示该通道的亮度最高。\n全连接神经网络在图像识别中的问题\r从全连接神经网络的结构我们不难看出，图片是一个二维数组，而全连接神经网络的输入层是一个一维数组，所以我们需要将图片展开成一个一维数组，才能输入到全连接神经网络中。 但是，将图片展开成一个一维数组会导致一个问题，就是图片的空间信息会丢失。\n例如，一张图片是一个28x28的灰度图片，展开成一个一维数组就是784个元素，每个元素就是一个像素点的灰度值。 但是，我们可以看出，图片中存在着空间信息，例如，一个像素点的灰度值和它的邻居像素点的灰度值是相关的。\n如果我们将图片展开成一个一维数组，那么这些空间信息就会丢失，模型就无法利用这些空间信息来进行识别。 为了解决上面的问题，我们需要引入卷积这个操作来提取图片的空间信息，以保留图片的空间结构特征。\n卷积层\r卷积运算\r不加偏置项的卷积运算\r卷积运算的过程就是将卷积核在图片上滑动，每次滑动一个像素，计算卷积核和图片上对应位置的元素的乘积，然后将这些乘积相加，得到卷积结果。 总结就一句话，先相乘，在相加\n加入偏置项的卷积运算\r加入偏置项的卷积运算就是在卷积运算的基础上，加上一个偏置项b，最终的卷积结果就是卷积核和图片上对应位置的元素的乘积的和再加上偏置项b。\n填充\r填充就是在图片的边界上添加一些像素点，以保持卷积后的图片大小不变。\n步幅\r步幅就是卷积核在图片上滑动的步长，步幅越大，卷积后的图片越小。\n卷积公式\r卷积公式就是根据卷积核的大小、填充、步幅等参数，计算出卷积后的图片大小。\n多通道卷积\r多通道卷积就是在每个通道上进行卷积运算，最后将所有通道的卷积结果合并起来。\n利用立体图来表示卷积\r池化\r最大池化\r最大池化就是在每个池化窗口中，取窗口内的最大值作为池化结果。\n平均池化\r平均池化就是在每个池化窗口中，取窗口内的平均值作为池化结果。\n其实池化后的特征图大小的计算公式跟卷积是一样的，是通用的而且及其重要。\n卷积神经网络的整体结构\r总结\r卷积神经网络其实就是在全连接神经网络的基础上迭代而来的，它解决了全连接神经网络在图像识别中的问题，即图片的空间信 …","date": "2025-11-05 15:00:00",
    "updated": "2025-11-05 15:00:00"
  }, 
  {
    "objectID": "f39e7c3061801b6c2e3b38f34df2fecb6b257190",
    "permalink": "/post/no.5/",
    "title": "CNN卷积神经网络算法原理：第二章","content": "\r前向传播\r如下图所示，这就是神经网络前向传播的计算过程\n而下图所示，是一个具体的前向传播计算过程\n损失函数\r在神经网络中我们一般使用的是均方误差损失函数，公式如下：\n反向传播\r如下图所示，这就是神经网络反向传播的一个案例\n通常反向传播的计算过程如下： 1. 求参数的梯度 2. 利用参数的梯度进行更新 3. 新参数的前向传播\n下面我们就根据一个简单的案例来具体演示一下反向传播的过程。\n求参数的梯度\r利用参数的梯度进行更新\r新参数的前向传播\r总结\r神经网络反向传播的过程就是根据损失函数对参数的梯度，利用梯度下降法对参数进行更新，运用新的参数进行前向传播，从而不断的去优化模型，直到模型的损失函数收敛到一个最优解。\n","date": "2025-11-04 15:00:00",
    "updated": "2025-11-04 15:00:00"
  }, 
  {
    "objectID": "58cdda505b18fd1ab2ebbf7e0c0fe01430bbdaa5",
    "permalink": "/post/no.4/",
    "title": "CNN卷积神经网络算法原理：第一章","content": "\r全连接神经网络整体结构\r全连接神经网络的整体结构如下：\n上述图片就是一个全连接神经网络的整体结构，它基本上有以下几个部分：\n输入层：输入层主要是接收外部输入的数据 隐藏层：隐藏层可以有多个，每个隐藏层由多个神经元组成，每个神经元接收来自上一层的所有节点的输入 输出层：输出层的节点数等于分类的类别数，每个节点对应一个类别。 全连接神经网络的单元结构\r每个神经元的计算过程如下：\n由图中不难看出，它的计算过程神似我们大脑中的神经元结构，这也就是为啥要叫全连接神经网络。 全连接神经网络与卷积神经网络的区别就是其中的神经元，其中CNN卷积神经网络的神经元其实就是一个个卷积核，将全连接神经网络中的每个神经元都替换为卷积核，就得到了卷积神经网络。\n激活函数\r激活函数的作用就是将神经元的输出映射到一个指定的范围，常用的激活函数有sigmoid函数、tanh函数、ReLU函数等。\n为啥要加入激活函数呢？ 其一因为如果不加入激活函数，那么神经网络就变成了一个线性模型，无法解决非线性问题。 其二就是加入激活函数可以使神经网络的输出在一个指定的范围内，这对于分类问题尤为重要。 其三就是加入激活函数可以使神经网络的训练更加高效，因为激活函数的导数在大部分情况下都是一个常数，这就使得反向传播算法的计算更加简单。\nsigmoid函数\rsigmoid函数的图像如下：\ntanh函数\rtanh函数的图像如下：\nReLU函数\rReLU函数的图像如下：\nLeaky ReLU函数\rLeaky ReLU函数的图像如下：\n总结\r这一章简单介绍了一下全连接神经网络的整体结构、单元结构、激活函数，以及它们的作用。\n","date": "2025-11-03 15:00:00",
    "updated": "2025-11-03 15:00:00"
  }, 
  {
    "objectID": "95515b1ac18353ab95200c470beac299822046d0",
    "permalink": "/post/no.3/",
    "title": "线性回归模型案例的代码复现","content": "\r案例\r上述就是我们要解决的问题，即通过线性回归模型来对未知的y值进行预测。下面我们将通过代码复现一下这个案例。\n代码复现\r# 定义数据集 # 定义数据特征 x_data = [1, 2, 3] # 定义数据标签 y_data = [2, 4, 6] # 初始化参数W w = 4 #定义线性回归模型 def forword(x): return x * w #定义损失函数 def cost(xs, ys): costvalue = 0 for x , y in zip(xs, ys): y_pred = forword(x) costvalue += (y_pred - y)**2 return costvalue / len(xs) #定义计算梯度的函数 def gradient(xs, ys): grad = 0 for x, y in zip(xs, ys): grad += 2 * x * (x * w - y) return grad / len(xs) for epoch in range(100): #计算误差损失 cost_val = cost(x_data, y_data) grad_val = gradient(x_data, y_data) w =w-0.01 * grad_val print(\u0026#39;训练轮次：\u0026#39;, epoch, \u0026#34;w=\u0026#34;, w,\u0026#34;loss\u0026#34;, cost_val) 结果\r运行上述的代码，我们不难得出当w接近2时，损失函数也接近0，这也验证了我们的模型是正确的。\n","date": "2025-11-02 15:00:00",
    "updated": "2025-11-02 15:00:00"
  }, 
  {
    "objectID": "4981202e06eb49e7473b6db82030b5bac0fff769",
    "permalink": "/post/no.2/",
    "title": "梯度更新","content": "\r梯度下降法\r根据上一篇的文章我们知道，我们可以用最小二乘法根据损失函数与参数w来求w的最优解。具体该怎么做呢？我们可以联想到以下的场景：\n我们根据以上场景，再结合损失函数与参数w的关系，我们可以得到下图中的公式\n该公式就是梯度下降法的公式，但其中具体是怎么来到这就可以参考高中数学的微积分中的微分原理。\n上图就是一个简单的微分原理演示图，其中我们不难看出梯度下降法中的a可以类比为微分中的∆Xm，而我们该如何求出这一段X值所对应的y值呢，其实很简单，我们拿最近简单一阶方程y=kx举例，我们对X进行求导，就可以得到k的值，而对应的y值就是k*Xm。 而在梯度下降法中，在我们给定一个初始值w0后，我们就可以根据梯度下降法的公式，不断的去更新w0，直到w0收敛到一个最优解。也就是图像中的最低点所以在梯度下降法中，学习率a对模型的影响极大，它不仅影响了模型的收敛速度，还影响了模型的精度；当我们设置a时要慎重考虑。\n案例求解\r下面我们根据以上梯度下降法的求解过程，对上一篇文章中的案例进行求解 参考以下的案例，我们不难求解出上一篇文章中的案例，以下的图片就是求解过程 总结\r根据上述论断我们不难看出梯度下降法实际上就是根据微分的思想，将我们寻找损失函数的最小值的过程，在a的控制下，进行不断的细化拆分，直到我们找到一个最优解。\n","date": "2025-11-01 15:00:00",
    "updated": "2025-11-01 15:00:00"
  }, 
  {
    "objectID": "9bc61343927d1df4cc49649fdcf243c9cb58447f",
    "permalink": "/post/no.1/",
    "title": "线性回归原理详解","content": "\r线性回归模型\r参考人类的学习方式，我们一般学会识别一个物体，都是通过观察大量的样本，然后根据样本中的特征进行识别的；同理机器学习也是如此，其中我们将事物的名称命名为标签及为y或，而特征则为x。机器学习就是通过学习大量的样本，然后根据样本中的标签去获得样品的特征，从而对新的样本进行预测。 就像我们如何判断一个人是否为男性，我们一般会根据他的特征来判断，比如他是否有长的头发、是否有喉结等；而机器学习就是通过学习大量的样本，然后根据样本中的特征去判断新的样本是否为男性。 所以线性回归模型就可以简化为y关于x的求解，就是已知x，然后根据x去预测y。而机器学习的目的就是确定x的系数，从而对新的样本进行预测。\n案例\r如同以上案例，我们希望通过已有的学习时间，去预测未知学习时间的考试分数。\n误差函数\r参考上述的案例，我们根据学习时间和考试分数的落点分布，设线性回归函数，同时为了避免我们获得的结果与现实的结果出现很大的偏差，我们需要引入误差函数。误差函数的作用就是衡量我们获得的结果与现实的结果之间的差异，从而判断我们的解是否准确。下面我们就对该回归函数求解\n穷举法\r穷举法是一种简单的求解方法，它的基本思想是：在所有可能的解中，选择一个最优解。但当我们的解空间很大时，穷举法的效率就会很低。所以我们引入了其他的求解方法，那个方法就是最小二乘法\n最小二乘法\r我们根据穷举法可以画出误差函数的图像，而最小二乘法的基本思想就是：在所有可能的解中，选择一个使得误差函数最小的解。以这个解为基础，我们可以得到线性回归函数的系数。\n求解\r下面我们根据以上最小二乘法的求解过程，对线性回归模型进行求解\n","date": "2025-10-30 15:00:00",
    "updated": "2025-10-30 15:00:00"
  }]